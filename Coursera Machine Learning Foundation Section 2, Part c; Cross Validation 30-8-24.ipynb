{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce41cba4",
   "metadata": {},
   "source": [
    "### Coursera Machine Learning Foundation\n",
    "#### Section 2, Part c: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b393fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf8e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/data/boston_housing_clean.pickle\"\n",
    " \n",
    " \n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    " \n",
    "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
    " \n",
    "boston = pickle.load(open('boston_housing_clean.pickle', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a412ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataframe', 'description'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46d4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = boston['dataframe']\n",
    "boston_description = boston['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddccab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b070a",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "Suppose we want to do Linear Regression on our dataset to get an estimate, based on mean squared error, of how well our model will perform on data outside our dataset.\n",
    "\n",
    "Suppose also that our data is split into three folds: Fold 1, Fold 2, and Fold 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a26990",
   "metadata": {},
   "source": [
    "#### Coding this up\n",
    "The KFold object in SciKit Learn tells the cross validation object (see below) how to split up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e10e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_data.drop('MEDV', axis=1)\n",
    "y = boston_data.MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c830bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(shuffle=True, random_state=72018, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb0dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [ 1  3  4  5  7  8 10 11 12 13] 337\n",
      "Test index: [ 0  2  6  9 15 17 19 23 25 26] 169\n",
      "\n",
      "Train index: [ 0  2  6  9 10 11 12 13 15 17] 337\n",
      "Test index: [ 1  3  4  5  7  8 14 16 22 27] 169\n",
      "\n",
      "Train index: [0 1 2 3 4 5 6 7 8 9] 338\n",
      "Test index: [10 11 12 13 18 20 21 24 28 31] 168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"Train index:\", train_index[:10], len(train_index))\n",
    "    print(\"Test index:\",test_index[:10], len(test_index))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b406bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.671934879847282, 0.7485020059212362, 0.6976807323597747]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "scores = []\n",
    "lr = LinearRegression()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = (X.iloc[train_index, :], \n",
    "                                        X.iloc[test_index, :], \n",
    "                                        y[train_index], \n",
    "                                        y[test_index])\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    score = r2_score(y_test.values, y_pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6beba3",
   "metadata": {},
   "source": [
    "#### Discussion (Part 2):\n",
    "Now suppose we want to do the same, but appropriately scaling our data as we go through the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706aa09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6719348798472715, 0.748502005921238, 0.6976807323597747]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "lr = LinearRegression()\n",
    "s = StandardScaler()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = (X.iloc[train_index, :], \n",
    "                                        X.iloc[test_index, :], \n",
    "                                        y[train_index], \n",
    "                                        y[test_index])\n",
    "    \n",
    "    X_train_s = s.fit_transform(X_train)\n",
    "    \n",
    "    lr.fit(X_train_s, y_train)\n",
    "    \n",
    "    X_test_s = s.transform(X_test)\n",
    "    \n",
    "    y_pred = lr.predict(X_test_s)\n",
    "\n",
    "    score = r2_score(y_test.values, y_pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8bb26",
   "metadata": {},
   "source": [
    "same scores, because for vanilla linear regression with no regularization, scaling actually doesn't matter for performance)\n",
    "\n",
    "This is getting quite cumbersome!\n",
    "\n",
    "Very luckily, SciKit Learn has some wonderful functions that handle a lot of this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9c668",
   "metadata": {},
   "source": [
    "#### Pipeline and cross_val_predict\n",
    "Pipeline lets you chain together multiple operators on your data that both have a fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c2e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([(\"scaler\", s),\n",
    "                      (\"regression\", lr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ebd9c",
   "metadata": {},
   "source": [
    "#### cross_val_predict\n",
    "cross_val_predict is a function that does K-fold cross validation for us, appropriately fitting and transforming at every step of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e3aaf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=72018, shuffle=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f157a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(estimator, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e0f51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7063531064161561"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a075a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060392060427615"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores) # almost identical!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75386ce1",
   "metadata": {},
   "source": [
    "Note that cross_val_predict doesn't use the same model for all steps; the predictions for each row are made when that row is in the validation set. We really have the collected results of 3 (i.e. kf.num_splits) different models.\n",
    "\n",
    "When we are done, estimator is still not fitted. If we want to predict on new data, we still have to train our estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594f59f",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "##### Definition\n",
    "Hyperparameter tuning involves using cross validation (or train-test split) to determine which hyperparameters are most likely to generate a model that generalizes well outside of your sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff820b15",
   "metadata": {},
   "source": [
    "#### Mechanics\n",
    "We can generate an exponentially spaces range of values using the numpy geomspace function.\n",
    "\n",
    "np.geomspace(1, 1000, num=4)\n",
    "produces:\n",
    "\n",
    "array([    1.,    10.,   100.,  1000.])      \n",
    "Use this function to generate a list of length 10 called alphas for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d9d5a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.geomspace(1e-9, 1e0, num=10)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e531b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "coefs = []\n",
    "for alpha in alphas:\n",
    "    las = Lasso(alpha=alpha, max_iter=100000)\n",
    "    \n",
    "    estimator = Pipeline([\n",
    "        (\"scaler\", s),\n",
    "        (\"lasso_regression\", las)])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    \n",
    "    score = r2_score(y, predictions)\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10526f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-09, 0.7063531064981925),\n",
       " (1e-08, 0.7063531072356071),\n",
       " (1e-07, 0.7063531145602442),\n",
       " (1e-06, 0.7063531882052065),\n",
       " (1e-05, 0.7063539165191507),\n",
       " (0.0001, 0.706361268093463),\n",
       " (0.001, 0.706433467041546),\n",
       " (0.01, 0.7070865958083233),\n",
       " (0.1, 0.705838151167185),\n",
       " (1.0, 0.6512724532884888)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(alphas,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84347f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07170372e-01,  4.63952623e-02,  2.08588308e-02,  2.68854318e+00,\n",
       "       -1.77954207e+01,  3.80475296e+00,  7.50802707e-04, -1.47575348e+00,\n",
       "        3.05654279e-01, -1.23293755e-02, -9.53459908e-01,  9.39253013e-03,\n",
       "       -5.25467196e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso(alpha=1e-6).fit(X, y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc85e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06342255,  0.04916867, -0.        ,  0.        , -0.        ,\n",
       "        0.94678567,  0.02092737, -0.66900864,  0.26417501, -0.01520915,\n",
       "       -0.72319901,  0.00829117, -0.76143296])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso(alpha=1.0).fit(X, y).coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa8095",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Add PolynomialFeatures to this Pipeline, and re-run the cross validation with the PolynomialFeatures added.\n",
    "\n",
    "Hint #1: pipelines process input from first to last. Think about the order that it would make sense to add Polynomial Features to the data in sequence and add them in the appropriate place in the pipeline.\n",
    "\n",
    "Hint #2: you should see a significant increase in cross validation accuracy from doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83ee99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "scores = []\n",
    "alphas = np.geomspace(0.06, 6.0, 20)\n",
    "for alpha in alphas:\n",
    "    las = Lasso(alpha=alpha, max_iter=100000)\n",
    "    \n",
    "    estimator = Pipeline([\n",
    "        (\"scaler\", s),\n",
    "        (\"make_higher_degree\", pf),\n",
    "        (\"lasso_regression\", las)])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    \n",
    "    score = r2_score(y, predictions)\n",
    "    \n",
    "    scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "477ca86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(alphas, scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863f7724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9134777735196521"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n",
    "# make the model and train it on ALL the data\n",
    "# Then release it into the wild .....\n",
    "best_estimator = Pipeline([\n",
    "                    (\"scaler\", s),\n",
    "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "                    (\"lasso_regression\", Lasso(alpha=0.03))])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "best_estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d457a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -1.00309168e+00,  3.32679107e+00, -1.01840878e+00,\n",
       "       -2.56161421e+00,  1.12778302e+00, -1.72266155e+00, -5.37088506e-01,\n",
       "        4.39555878e-01, -3.39542586e+00,  7.22387712e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  3.53653554e+00, -0.00000000e+00,  3.72285440e-01,\n",
       "        0.00000000e+00,  0.00000000e+00, -5.49528703e-01, -0.00000000e+00,\n",
       "       -0.00000000e+00, -4.05522485e-02,  2.25864611e-01,  1.78508858e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  6.50874606e-02,\n",
       "       -0.00000000e+00, -2.07295802e-01, -0.00000000e+00,  3.71781995e-01,\n",
       "        0.00000000e+00, -0.00000000e+00, -5.89531100e-02,  3.47180625e-01,\n",
       "        0.00000000e+00,  9.23666274e-01,  3.48873365e-01,  7.29463442e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  7.68485586e-02, -7.21083596e-01,\n",
       "        0.00000000e+00, -5.98542558e-01,  4.18420677e-01, -7.98165728e-01,\n",
       "       -7.25062683e-01,  2.34818861e-01, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -1.68164447e-02,  0.00000000e+00, -4.04477826e-01,\n",
       "       -4.22989874e-01, -4.06983988e-01, -3.75443720e-01,  4.17684564e-01,\n",
       "       -8.91841193e-01,  0.00000000e+00, -2.69309481e-01,  0.00000000e+00,\n",
       "        1.02286785e-01,  2.02570379e-01, -6.88345376e-01, -0.00000000e+00,\n",
       "       -1.08598703e+00, -3.98751731e-01, -9.37684760e-01, -1.17343147e-01,\n",
       "       -7.37427594e-01,  0.00000000e+00,  0.00000000e+00,  1.36340670e+00,\n",
       "       -0.00000000e+00, -2.94691228e-03, -8.98125013e-01, -8.68198373e-01,\n",
       "        8.03396788e-01, -1.91683803e-01, -1.14706070e-01,  0.00000000e+00,\n",
       "       -0.00000000e+00,  5.83161589e-01, -0.00000000e+00,  5.81365491e-02,\n",
       "        0.00000000e+00, -2.32896159e-01, -1.12440837e+00,  0.00000000e+00,\n",
       "        1.96286997e+00, -0.00000000e+00, -1.00915801e+00, -7.04656486e-02,\n",
       "       -1.06456357e-02, -4.78389591e-02, -3.97645601e-01, -3.84121840e-01,\n",
       "        9.97402419e-01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator.named_steps[\"lasso_regression\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab89fe",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Do the same, but with Ridge regression\n",
    "\n",
    "Which model, Ridge or Lasso, performs best with its optimal hyperparameters on the Boston dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25f38ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x263e0569dd0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABE/0lEQVR4nO3de1xUdf4/8NfMAMNFmBG5C3LxBopX0JRLphZmplmZbKXmrc3fWoaaW25mG2uRVq6rrrT6NcvNVlczszJbvKSimYSCpgJekDuMojAjd2bO7w9gkgBlcOAwM6/n4zEP48w5M++TOvPyc5UIgiCAiIiIyMRJxS6AiIiIyBgYaoiIiMgsMNQQERGRWWCoISIiIrPAUENERERmgaGGiIiIzAJDDREREZkFhhoiIiIyC1ZiF9CRdDod8vPz4ejoCIlEInY5RERE1AqCIECj0cDLywtSacvtMRYVavLz8+Hj4yN2GURERNQGOTk58Pb2bvF5iwo1jo6OAOr+pzg5OYlcDREREbWGWq2Gj4+P/nu8JRYVahq6nJycnBhqiIiITMy9ho5woDARERGZBYYaIiIiMgsMNURERGQWGGqIiIjILDDUEBERkVlgqCEiIiKzwFBDREREZoGhhoiIiMwCQw0RERGZBYYaIiIiMgsMNURERGQWGGqIiIjILFjUhpZERMZ0u6oWWcVlKCipRK1OgCAI0AmAThCgEwQI+v9G/c93Po+6n3V3Pt+K84XfnV9/vdxaCk+FLTycbOGhqHu4OMghld59A0Aic8JQQ0R0F6UVNcgqLsO14nJk3aj/tf7nG7erxC7vrqykErjfEXI87/xvhS08FHZwc5TDWsZGezIPDDVEZNEEQcCt8hpcKy6rCys3fgstWcVluFVec9frnR1s0F1pBxsrKWQSCSQSQCqRQCqt+1UikUDacEyC3/18x/mSZs6Xtv78sqpaFKorUVhaiUJ1JVSaKtTqBOSVVCCvpKLF+iUSwKWLvEkrj6fCFu5OtvBU2MHDyRZ2NjJj/68nMjqGGiIye4Ig4LqmSh9UsorL60NM3a+aytq7Xu/qKIdfN3v4dnO441cH9OhmD4WddQfdhWFqtDpc11Tpg05BaSUKSytQqK5CYWkFCkorUaSuRI227v/NdU0VzqK0xddT2lvrQ89vgaeutafhuJOtFSQSdneReBhqiMgsCIKAQnUlMm/cEVpu1P2afbMc5dXau17vqbCFbzd7+HVzaBRefLvZw0Fueh+V1jIpvJR28FLatXiOTifgZnn1b6FHXakPPA0tPgUllaio0aKkvAYl5TVIK9S0+Hr2NjJ96AnycMJAHyUGeyvh42zHsEMdQiIIgiB2ER1FrVZDoVCgtLQUTk5OYpdDRPepskaLnzNv4nCaCofTVcgqLm/xXKkE6N7VDr7ODneEF3v4uTigh7M9bK3ZvdIcQRCgrqxFkfq31p6GVp47w0/JXbrputpbY6C3EoN8lBjso8BAbyVcusg78C7I1LX2+5uhhohMSl5JBQ6nqfBjugrHLxejoua3FhiZVIIezvaNQ0v9r95d7WFjxQGx7aWiWlvXslNagdxbFfg1rxSpOSW4UKBGjbbp10x3pR0G+ygx0FuBQT5KDOiuMMkWMeoYDDXNYKghMj21Wh2Ss27hcPp1/JiuatL94e4kx+i+bhgd6IbwXi7owi/GTqWqVou0Ag1Sc0uQklOCs7mluHL9Nn7/zSOVAL3cumBQfYvOIG8l+no4MogSAIaaZjHUEJmG4ttV+DH9Og6lq3As4zrUdwzklUqAIT26YnRfV4wOdEM/TyeO1zAx6soa/JpbitTcutac1NwSFJRWNjnPxkqK/l5O9UFHgUHeSvh1c+DaOxaIoaYZDDVEnZNOJ+DX/FIcTqsLMmdzSxr9S15pb42H+tSFmAd7u6Krg414xVK7UKkrkZpbirP1LTqpOSWNwmwDR1urRiFnkI8S7k62IlRMHYmhphkMNUSdh7qyBomXbuBQmgo/pl9vspBdP08njAms61Ya7KOEjP86tyiCICCruLxRt9WveaWoqtU1OdfDyRaD6gcgD/ZRYoC3Ak62nXOqPbUNQ00zGGqIxCMIAi6rbuNQ/UylX67dQq3ut48fBxsZInq7YHRfNzzU1w0eCv7rmxqr0eqQXqjB2Tu6rTKKNNA18y0W4OqAwd6/DUQO8nTiDDcTxlDTDIYaoo5VWaPFiSs3cDjtOg6nq5B7q/HKtgGuDhjd1w1jAt0wzM+Zg0LJYOXVtfg1T/1bt1VuCXJuNl1B2VomQaCHE4b2UOKhQDeMDOjGkGNCGGqawVBD1DFU6kpsOXENn5/MarRar42VFCMCumFM/SBf324OIlZJ5upmWTVSc+vG5TS06hSXVTc6x85ahvBeLng4qK6Lk+NyOjeGmmYw1BC1ryvXb2PT0avYfToP1dq6sQ+eCtu6sTF93RDWqxvsbTjlmjqWIAjIvVWB1NwS/HSlGIfSVE1mWw3orsCYQDeMDXJDsJeCM6w6GYaaZjDUELWP5Kxb+NeRK0i4WKSftTS0hxLzRvXEw0Hu/IKgTkUQBFws0ODgxSIcTFMh9Xez7Vwd5RjT1w1jgtwQ0cuFiwJ2Agw1zWCoITIenU7AoTQV/nX0CpKu3dIffzjIHfNGBSDUz1nE6oha77qmCj+mq3AoTYWjGddRdsc+YTZWUowM6IaxQXVjv7y72otYqeViqGkGQw3R/auq1eLrlHxsPHoVl1W3AdQNwnxySHf88cEA9HJzFLlCorarqtUiKfMWDlwswsG0oiaDjvu6O2JMkBvGBrphSI+uXGqggzDUNIOhhqjt1JU1+M/P2fjkeCaK1HVryjjKrfDciB6YHe7PgZZkdgRBwJXrt3HwogoH01RIzroF7R3zx7vaW9fN3gtyw4N9XLk2TjtiqGkGQw2R4YrUlfjkeCa+OJkNTVXdTCY3RznmRPjj2Qd68IOcLEZJeTWOZFzXLxhZWvHbzuRWUgmG+Tnru6kCXLuIWKn5YahpBkMNUetdVmmw8ehVfHUmT7/Lci+3LvjjgwF4YrAX5FZc44MsV8NGq4fS6lpxGrpiG/i7OGBsYF0rzjA/Z1jLuAbT/WCoaQZDDdG9/XLtJj4+chUHLhbpjw3z64qXHuyJMYFunMlE1Iys4rK6gHNRhZ8zi/X/EADqumkf7OuKsYF1q2U7c+8ygzHUNIOhhqh5Op2AAxeL8K+jV5Gc9dtMpqh+7nhpVABCfDmTiai1NPX7mh1MU+FwmqrRwn8SCTC0R1eMCXTDw0Hu6OPehbvMtwJDTTMYaogaq6rVYs+ZPPzr6FVcvV4GALCRSfHU0O6YGxmAXm4cF0B0P3Q6Aam5JTiUpsKBiypcLFA3er670k4/DmcEt25oEUNNMxhqiOpU1mjx6Ylr+CQxEypN/UwmWytMG+GLWWF+cONMJqJ2kV9SgUNpdWviHL98o9Gu43bWdZu6jg2sCzn8e/ib1n5/t2nk0oYNG+Dv7w9bW1uEhITg2LFjdz1/27ZtGDRoEOzt7eHp6YlZs2ahuLhY//ynn34KiUTS5FFZ2XgZa0Pfl4iaOpV5E+P/cQzvf58GlaYKHk62ePOxIJx4YwxefzSQH6RE7chLaYdpI3zxycxhSFkehc0vhOLZ4T3g7iRHRY0WCReK8Mbuc3gg7iCmb/4ZX6fkoeKOxQDp7gxe+3nHjh2IiYnBhg0bEB4ejn/9618YP348Lly4gB49ejQ5PzExETNmzMDf//53TJw4EXl5eZg3bx7mzp2Lr776Sn+ek5MT0tPTG11ra/vbh6uh70tEjd2uqsXK79Pw75NZAOqmZb82ri8mD+7O3bGJRGBnI8PYIHeMDXKHIATjfL66frBxEVJzS3Hs0g0cu3QDXeRWeHygJ6aEeCPEtyvH4NyFwd1PDzzwAIYOHYr4+Hj9saCgIEyePBlxcXFNzv/www8RHx+PK1eu6I+tW7cOq1atQk5ODoC6lpqYmBiUlJQY7X2bw+4nslRHMq7jL7vPIa+kbnXU6FAf/GVCEBR2XGOGqDPKLi7Hl6dz8eXpXOTe+m1VY79u9nh6qDeeHNrdorZsaJfup+rqaiQnJyMqKqrR8aioKJw4caLZa8LCwpCbm4t9+/ZBEAQUFRVh165dmDBhQqPzbt++DV9fX3h7e+Pxxx/HmTNn7ut9AaCqqgpqtbrRg8iSlJRXY/F/U/HCJ6eQV1IBH2c7bJv7AFZOGchAQ9SJ9ehmj4WP9MHRJaOx/Y8jMCXEG/Y2MlwrLsdHCRmIWHkYz206id2nc1FeXSt2uZ2GQaHmxo0b0Gq1cHd3b3Tc3d0dhYWFzV4TFhaGbdu2ITo6GjY2NvDw8IBSqcS6dev05wQGBuLTTz/F3r178Z///Ae2trYIDw/HpUuX2vy+ABAXFweFQqF/+Pj4GHK7RCZt/68FeHj1UXx5OhcSCTAr3A8/xDyI8F4uYpdGRK0klUowIqAbPnxmEJLefBgfPTMIIwO6AQBOXCnGov+mYtiKA1iyMxU/Xy2GTmcxc3+a1ab91H/fnycIQot9fBcuXMCCBQuwfPlyjBs3DgUFBViyZAnmzZuHzZs3AwBGjBiBESNG6K8JDw/H0KFDsW7dOqxdu7ZN7wsAS5cuxaJFi/Q/q9VqBhsyeypNJd7++jy+/7Uu8Pd0dcCqKQO51gyRiXOQW+HpEG88HeKNnJvl+OpMHnYl5yL7Zjl2JudiZ3IufJzt8PRQbzw91Bs+zpbTPdXAoFDj4uICmUzWpHVEpVI1aUVpEBcXh/DwcCxZsgQAMHDgQDg4OCAyMhIrVqyAp6dnk2ukUimGDRumb6lpy/sCgFwuh1wuN+QWiUyWIAjYfToPsd9eQGlFDWRSCeaNCsArY3pz7QsiM+PjbI8FY3vjlTG98EvWLez6JRffnStAzs0KrDlwCWsOXMID/s6YEuKNxwZ4wkHepjYMk2NQ95ONjQ1CQkKQkJDQ6HhCQgLCwsKavaa8vBxSaeO3kcnqPmBbGqMsCAJSUlL0gact70tkSfJKKjDr0yQs3pmK0ooa9PN0wtfzw7FkXCADDZEZk0jqNtJcOWUgkt58GGuiByOilwskEuDnzJtYsussQlccwKL/puDElRtm3z1lcHRbtGgRpk+fjtDQUIwcORIbN25EdnY25s2bB6CuyycvLw9bt24FAEycOBEvvvgi4uPj9d1PMTExGD58OLy8vAAA77zzDkaMGIHevXtDrVZj7dq1SElJwT//+c9Wvy+RJdLpBGw7lY33911EWbUWNjIpXn24N/74YAA30COyMHY2Mkwe0h2Th3RHfkmFvnsq80YZdp/Ow+7TeeiutMPTQ7vjqaHe8HNxELtkozM41ERHR6O4uBixsbEoKChAcHAw9u3bB19fXwBAQUEBsrOz9efPnDkTGo0G69evx+LFi6FUKjFmzBisXLlSf05JSQn++Mc/orCwEAqFAkOGDMHRo0cxfPjwVr8vkaXJvFGG1788i1OZNwEAIb5dsfLpgdzagIjgpbTD/NG98KeHeuJ0dgl2Jefi29R85JVUYO2hy1h76DKG+XXVd0852prHbEhuk0BkYmq1OnxyPBMf/S8DVbU62FnL8OdH+2LGSD/IuIM2EbWgskaL/10owq7kXCReuo6Gnihbayke7e+BKSE+GNmzW6f8HOHeT81gqCFTl1aoxuu7ziI1txQAENHLBXFPDbDIWQ5E1HaFpZX13VM5uFK/mS0AeCps8dTQ7nh6qDcCXDtPqy9DTTMYashUVdfq8M/Dl7Hhx8uo0QpwtLXCsglBmBrqwyXTiajNBEFAam4pdiXnYG9KPtSVvy3kN7SHElNCfDBhoKfoi3Uy1DSDoYZMUWpOCf686yzSizQAgIeD3PHuk8Fw58aTRGRElTVaHLyowq7kHBzJ+K17ysZKinH9PTAlxBsRvVxE6Z5iqGkGQw2ZksoaLVYnZOD/jl2FTgC6Odjgr5P64/GBnmydIaJ2pVJXYk9K3eypjKLb+uPuTnI8OcQbU0K6o5ebY4fVw1DTDIYaMhUqTSXmfvYLztaPnXlisBfentgfzg42IldGRJZEEAT8mqfGruQcfJ2aj5LyGv1zg3yUmBLijUkDvaCwb9/uKYaaZjDUkCnIKNJg1pYk5JVUoKu9NT6YMggP92t55Wwioo5QVavF4TQVdiXn4nD6dWjr+6dsZFI80s8dU0K8EdnbBVbtsEYWQ00zGGqoszt++QbmfZ4MTWUt/F0csGXmMLNcIIuITNt1TRW+ru+eSivU6I+7OsqxZeYwBHdXGPX9Wvv9bRmbQRCZgP/+koO/7D6HWp2AYX5dsXF6KLqyu4mIOiFXRznmRgZgbmQAzueXYldyLr5OyUd5VS0CXMX7hxhDDZHIBEHA6oQMrDt0GQAwaZAXVk0ZyD2biMgk9PdSoL+XAkvHByGjSAN7G/GiBUMNkYiqarX4866z+DolHwDwypheWPRIH85uIiKTY2MlNXq3k6EYaohEcqusGi/9Oxmnrt2ElVSC954cgKnDfMQui4jIZDHUEIkgq7gMs7Yk4eqNMjjKrRA/LQQRvV3ELouIyKQx1BB1sOSsm3hxazJullWju9IOn8wchr4eHbeIFRGRuWKoIepA350twML/pqC6VocB3RXY/EIo3LjdARGRUTDUEHUAQRDwr6NX8f73aQDq9m9a++xgUWcJEBGZG36iErWzWq0Ob319Hv85lQ0AmBXuh2UT+omyKRwRkTljqCFqR5rKGsz/4gyOZlyHRAIsf7wfZoX7i10WEZFZYqghaif5JRWY/WkS0go1sLOWYe2zQ/AI93AiImo3DDVE7eDXvFLM+SwJReoquHSR45OZoRjorRS7LCIis8ZQQ2Rkh9NUmP/FaZRXa9HHvQs+mTkM3l3txS6LiMjsMdQQGdG/f7qGt/eeh04Awnt1w4bnQ6Cwsxa7LCIii8BQQ2QEOp2AuO8vYtOxTADAMyHeePfJAbCxkopcGRGR5WCoIbpPtVodXt2egu/OFQAAXovqg/mje3FTSiKiDsZQQ3QfBEHA0t3n8N25AtjIpPjgmYF4YnB3scsiIrJIDDVE92HVD+nYmZwLqQT45/NDOWWbiEhE7PAnaqPNiZmI//EKACDuqQEMNEREImOoIWqDPWfy8LdvLwAAlozri+hhPUSuiIiIGGqIDPRjugqv7UwFULeP058e6ilyRUREBDDUEBnkTPYt/L/PT6NWJ2DSIC+8NaEfZzkREXUSDDVErXRZdRuzP01CRY0Wkb1d8OEzgyDlTttERJ0GQw1RKxSUVuCFT07hVnkNBnkr8PG0EC6sR0TUyfBTmegeSsqr8cInp5BXUoEAFwd8MnMYHORcDYGIqLNhqCG6i4pqLeZ89gsyim7D3UmOrXOGo1sXudhlERFRMxhqiFpQq9Xh5S9OIznrFpxsrbB19gPcbZuIqBNjqCFqRsP2BwfTVJBbSbF55jD09XAUuywiIroLhhqiZqzcX7f9gUwqwfrnhmKYn7PYJRER0T0w1BD9zv8du4qPj9Rvf/Aktz8gIjIVDDVEd/jqTC5WfHcRAPDnR/ti6jAfkSsiIqLWYqghqvdjugpLdp4FAMwO98f/G8XtD4iITAlDDREab3/wxGAvLJsQxO0PiIhMDEMNWbw7tz94sI8rPpjC7Q+IiEwRQw1ZtILSCszY/HPd9gc+SsQ/P5TbHxARmSh+epPFKimvxozNp5BfWokAVwds4fYHREQmjaGGLFLD9geXVLfh4WSLrbOHw9nBRuyyiIjoPjDUkMURBAF//vKsfvuDz2YP5/YHRERmgKGGLM6OpBx8k5oPK6kE//cCtz8gIjIXDDVkUTKKNPjrN+cBAK+N64vh/tz+gIjIXDDUkMWoqNbi5S9Oo7JGhwf7uOKPkQFil0REREbEUEMWI/bb88goug1XRzlWT+VaNERE5oahhizCN6n5+M+pHEgkwJrowXDpIhe7JCIiMjKGGjJ72cXl+MvucwCA+Q/1QngvF5ErIiKi9sBQQ2atulaHV/5zGpqqWoT6dkXMw73FLomIiNoJQw2ZtQ9+SENqbikUdtb4x7NDYCXjH3kiInPFT3gyW4fTVNh0LBMA8MGUgeiutBO5IiIiak8MNWSWCksrsXhnKgBgZpgfovp7iFwRERG1N4YaMjtanYCYHWdws6wa/Tyd8Mb4QLFLIiKiDtCmULNhwwb4+/vD1tYWISEhOHbs2F3P37ZtGwYNGgR7e3t4enpi1qxZKC4ubvbc7du3QyKRYPLkyY2OazQaxMTEwNfXF3Z2dggLC0NSUlJbyicz98/Dl3Hy6k3Y28iw/rkhsLWWiV0SERF1AINDzY4dOxATE4M333wTZ86cQWRkJMaPH4/s7Oxmz09MTMSMGTMwZ84cnD9/Hjt37kRSUhLmzp3b5NysrCy89tpriIyMbPLc3LlzkZCQgH//+984d+4coqKi8PDDDyMvL8/QWyAz9vPVYqw5kAEAWDE5GAGuXUSuiIiIOopEEATBkAseeOABDB06FPHx8fpjQUFBmDx5MuLi4pqc/+GHHyI+Ph5XrlzRH1u3bh1WrVqFnJwc/TGtVotRo0Zh1qxZOHbsGEpKSrBnzx4AQEVFBRwdHfH1119jwoQJ+msGDx6Mxx9/HCtWrGhV7Wq1GgqFAqWlpXBycjLktskE3Cqrxvh/HEOhuhJPD/XGR1MHiV0SEREZQWu/vw1qqamurkZycjKioqIaHY+KisKJEyeavSYsLAy5ubnYt28fBEFAUVERdu3a1SicAEBsbCxcXV0xZ86cJq9RW1sLrVYLW1vbRsft7OyQmJjYYr1VVVVQq9WNHmSeBEHAaztTUaiuRICrA2Kf6C92SURE1MEMCjU3btyAVquFu7t7o+Pu7u4oLCxs9pqwsDBs27YN0dHRsLGxgYeHB5RKJdatW6c/5/jx49i8eTM2bdrU7Gs4Ojpi5MiR+Nvf/ob8/HxotVp8/vnn+Pnnn1FQUNBivXFxcVAoFPqHj4+PIbdLJmTL8Ws4mKaCjZUU654dAge5ldglERFRB2vTQGGJpPFGgIIgNDnW4MKFC1iwYAGWL1+O5ORk7N+/H5mZmZg3bx6AugHA06ZNw6ZNm+Di0vLy9f/+978hCAK6d+8OuVyOtWvX4rnnnoNM1vIg0KVLl6K0tFT/uLO7i8zHudxSxH1/EQCwbEIQ+nspRK6IiIjEYNA/Z11cXCCTyZq0yqhUqiatNw3i4uIQHh6OJUuWAAAGDhwIBwcHREZGYsWKFSgqKsK1a9cwceJE/TU6na6uOCsrpKeno2fPnujZsyeOHDmCsrIyqNVqeHp6Ijo6Gv7+/i3WK5fLIZdz40Jzpqmswcv/OY0arYBx/d0xfYSv2CUREZFIDGqpsbGxQUhICBISEhodT0hIQFhYWLPXlJeXQypt/DYNrSuCICAwMBDnzp1DSkqK/jFp0iSMHj0aKSkpTbqMHBwc4OnpiVu3buGHH37AE088YcgtkBkRBAHL9vyKrOJydFfaYdXTg1psMSQiIvNn8MCDRYsWYfr06QgNDcXIkSOxceNGZGdn67uTli5diry8PGzduhUAMHHiRLz44ouIj4/HuHHjUFBQgJiYGAwfPhxeXl4AgODg4EbvoVQqmxz/4YcfIAgC+vbti8uXL2PJkiXo27cvZs2a1aYbJ9O3MzkXX6fkQyaVYO2zg6Gwtxa7JCIiEpHBoSY6OhrFxcWIjY1FQUEBgoODsW/fPvj61jX7FxQUNFqzZubMmdBoNFi/fj0WL14MpVKJMWPGYOXKlQa9b2lpKZYuXYrc3Fw4Ozvj6aefxrvvvgtra36RWaLLKg3e/vo8AGDRI30Q4ussckVERCQ2g9epMWVcp8Y8VNZoMfmfx5FWqEFELxdsnT0cUim7nYiIzFW7rFND1Bn87dsLSCvUwKWLDVZHD2KgISIiAAw1ZGK+P1eAbT/XdW+unjoYbo6297iCiIgsBUMNmYzSihq8VT+OZt6onniwj6vIFRERUWfCUEMmY/X/0nHjdhUCXB2w8JHeYpdDRESdDEMNmYRzuaX498ksAMDfngiG3KrllaSJiMgyMdRQp6fVCVi25xx0AjBpkBfCe7W8nQYREVkuhhrq9LYnZSM1txRd5FZYNiFI7HKIiKiTYqihTu3G7Sqs2p8OAFgc1QduTpztREREzWOooU7t/e/TUFpRg36eTtyskoiI7oqhhjqtU5k3sSs5FwCw4slgWMn4x5WIiFrGbwnqlGq0Ory151cAwLPDfTC0R1eRKyIios6OoYY6pU+PX0N6kQZd7a3x53GBYpdDREQmgKGGOp2C0gr8/UAGAGDp+CB0dbARuSIiIjIFDDXU6fzt2wsor9YixLcrpoR4i10OERGZCIYa6lR+TFdh37lCyKQSrJgczB24iYio1RhqqNOorNHi7b11G1bOCvNDkKeTyBUREZEpYaihTuPjI1eQVVwOdyc5Yh7pI3Y5RERkYhhqqFO4dqMMG368AgBY/nh/dJFbiVwRERGZGoYaEp0gCFi+9zyqa3WI7O2CxwZ4iF0SERGZIIYaEt3+XwtxNOM6bGRSxD4RDImEg4OJiMhwDDUkqttVtXjnmwsAgHkP9YS/i4PIFRERkaliqCFRrT14CYXqSvRwtsefHuopdjlERGTCGGpINOmFGmxOzAQAvPNEf9hay0SuiIiITBlDDYlCpxOwbM85aHUCHu3vgdF93cQuiYiITBxDDYniy9O5SLp2C/Y2Miyf2E/scoiIyAww1FCHKymvRtz3aQCAV8f2hpfSTuSKiIjIHDDUUIdb9UM6bpZVo7dbF8yO8Be7HCIiMhMMNdShzmTfwn9OZQMAVkwOhrWMfwSJiMg4+I1CHUarE7Bsz68QBODpod54IKCb2CUREZEZYaihDvPVmTycz1fDydYKSx8LFLscIiIyMww11CFqtDr842AGAGD+6F5w6SIXuSIiIjI3DDXUIXb+koucmxVw6SLHjJF+YpdDRERmiKGG2l1ljRbrDl0CAMwf3RN2Nlw5mIiIjI+hhtrd9lPZKCithKfCFs8O7yF2OUREZKYYaqhdVVRrsf7wFQDAy2N6cX8nIiJqNww11K62/nQNN25XwcfZDs+E+IhdDhERmTGGGmo3t6tq8fGRulaaBWN6w8aKf9yIiKj98FuG2s2WxEzcKq9BgIsDnhzSXexyiIjIzDHUULsoLa/BxmNXAQAxj/SBFbdDICKidsZvGmoX/5d4FZrKWvR1d8TjAzzFLoeIiCwAQw0Z3c2yanySmAkAWPhIH0ilEpErIiIiS8BQQ0b3ryNXUFatRXB3J4zr7y52OUREZCEYasioVJpKfPbTNQDA4kf6QiJhKw0REXUMhhoyqg2Hr6CyRochPZR4qK+r2OUQEZEFYagho8kvqcAXP2cDAF6LYisNERF1LIYaMpr1hy+jWqvDA/7OCOvZTexyiIjIwjDUkFFkF5fjv0k5AIDFbKUhIiIRMNSQUaw9dAm1OgGRvV0w3N9Z7HKIiMgCMdTQfbty/TZ2n84FUNdKQ0REJAaGGrpvaw5cgk4AHg5yx2AfpdjlEBGRhWKoofuSVqjGt2fzAQCLHukjcjVERGTJGGrovvw9IQOCAEwY4Il+Xk5il0NERBaMoYba7FxuKX44XwSJBIh5uLfY5RARkYVjqKE2W52QDgCYPLg7ers7ilwNERFZOoYaapPkrFs4nH4dMqkEr45lKw0REYmPoYbapKGVZspQb/i5OIhcDRERURtDzYYNG+Dv7w9bW1uEhITg2LFjdz1/27ZtGDRoEOzt7eHp6YlZs2ahuLi42XO3b98OiUSCyZMnNzpeW1uLZcuWwd/fH3Z2dggICEBsbCx0Ol1bboHuw09XinH8cjGsZRK8MraX2OUQEREBaEOo2bFjB2JiYvDmm2/izJkziIyMxPjx45Gdnd3s+YmJiZgxYwbmzJmD8+fPY+fOnUhKSsLcuXObnJuVlYXXXnsNkZGRTZ5buXIlPv74Y6xfvx4XL17EqlWr8MEHH2DdunWG3gLdB0EQ9K00fxjWA95d7UWuiIiIqI7BoWb16tWYM2cO5s6di6CgIKxZswY+Pj6Ij49v9vyTJ0/Cz88PCxYsgL+/PyIiIvDSSy/hl19+aXSeVqvF888/j3feeQcBAQFNXuenn37CE088gQkTJsDPzw9TpkxBVFRUk9eh9nXs0g0kXbsFuZUUL49hKw0REXUeBoWa6upqJCcnIyoqqtHxqKgonDhxotlrwsLCkJubi3379kEQBBQVFWHXrl2YMGFCo/NiY2Ph6uqKOXPmNPs6EREROHjwIDIyMgAAqampSExMxGOPPWbILdB92nTsKgDguQd6wN3JVuRqiIiIfmNlyMk3btyAVquFu7t7o+Pu7u4oLCxs9pqwsDBs27YN0dHRqKysRG1tLSZNmtSo2+j48ePYvHkzUlJSWnzv119/HaWlpQgMDIRMJoNWq8W7776LZ599tsVrqqqqUFVVpf9ZrVa38k6pOemFGhy7dANSCTA73F/scoiIiBpp00BhiUTS6GdBEJoca3DhwgUsWLAAy5cvR3JyMvbv34/MzEzMmzcPAKDRaDBt2jRs2rQJLi4uLb7njh078Pnnn+OLL77A6dOn8dlnn+HDDz/EZ5991uI1cXFxUCgU+oePj08b7pYabDmeCQAY198DPs4cS0NERJ2LRBAEobUnV1dXw97eHjt37sSTTz6pP/7qq68iJSUFR44caXLN9OnTUVlZiZ07d+qPJSYmIjIyEvn5+SgqKsKQIUMgk8n0zzfMaJJKpUhPT0fPnj3h4+ODN954A/Pnz9eft2LFCnz++edIS0trtt7mWmp8fHxQWloKJycu6W+I4ttVGPn+IVTX6rBr3kiE+jmLXRIREVkItVoNhUJxz+9vg7qfbGxsEBISgoSEhEahJiEhAU888USz15SXl8PKqvHbNAQYQRAQGBiIc+fONXp+2bJl0Gg0+Mc//qFvXSkvL4dUKm3yOneb0i2XyyGXy1t/g9SiL37ORnWtDgO9FQjx7Sp2OURERE0YFGoAYNGiRZg+fTpCQ0MxcuRIbNy4EdnZ2frupKVLlyIvLw9bt24FAEycOBEvvvgi4uPjMW7cOBQUFCAmJgbDhw+Hl5cXACA4OLjReyiVyibHJ06ciHfffRc9evRA//79cebMGaxevRqzZ89u041T61XVarH1ZBYAYE6Ef4tdjURERGIyONRER0ejuLgYsbGxKCgoQHBwMPbt2wdfX18AQEFBQaM1a2bOnAmNRoP169dj8eLFUCqVGDNmDFauXGnQ+65btw5vvfUW/vSnP0GlUsHLywsvvfQSli9fbugtkIG+TS3AdU0V3J3kGB/sKXY5REREzTJoTI2pa22fHP1GEAQ8vi4R5/PVWDKuL+aP5to0RETUsVr7/c29n+iufs68ifP5athaS/Hc8B5il0NERNQihhq6q08S66ZxPzXUG10dbESuhoiIqGUMNdSirOIyJFwsAgDMDvcTtxgiIqJ7YKihFn164hoEARjVxxW93BzFLoeIiOiuGGqoWerKGvw3KQdA3TRuIiKizo6hhpr136QclFVr0dutCyJ7t7x9BRERUWfBUENN1Gp12HL8GgBgNhfbIyIiE8FQQ00kXChCXkkFutpb48kh3cUuh4iIqFUYaqiJT+p3437+AV/YWsvucTYREVHnwFBDjZzNLUHStVuwlkkwfaSv2OUQERG1GkMNNdKw2N7jA73g7mQrcjVEREStx1BDeoWllfj2bAEAYHY4p3ETEZFpYaghva0/XUOtTsBwP2cM8FaIXQ4REZFBGGoIAFBRrcUXp7IB1E3jJiIiMjUMNQQA2H0mFyXlNfBxtsMj/dzFLoeIiMhgDDUEnU7QDxCeGeYPmZSL7RERkelhqCEcvXQdV66XoYvcClNDvcUuh4iIqE0Yagif1G+JMDXUB4621uIWQ0RE1EYMNRbuUpEGRzOuQyoBZoX7iV0OERFRmzHUWLiGLREe6ecOH2d7kashIiJqO4YaC3azrBq7T+cBAOZEBIhcDRER0f1hqLFgX/ychapaHYK7O2GYX1exyyEiIrovDDUWqrpWh60/ZQEA5kT4QyLhNG4iIjJtDDUW6vtfC6DSVMHNUY4JA7zELoeIiOi+MdRYqO2ncgAAzz3QAzZW/GNARESmj99mFijnZjl+uloMiQSYEsLF9oiIyDww1Figncm5AIDwni7w7spp3EREZB4YaiyMTifgy/pQ8wy3RCAiIjPCUGNhTlwpRl5JBRxtrTCuv4fY5RARERkNQ42F2ZlcN0D4icFesLWWiVwNERGR8TDUWJDSihrs/7UQAPBMiI/I1RARERkXQ40F+SY1H1W1OvR1d8RAb4XY5RARERkVQ40F2flLXdfTM6HeXEGYiIjMDkONhUgv1CA1txRWUgkmD+kudjlERERGx1BjIRpaacYGucGli1zkaoiIiIyPocYC1Gh1+OpMHgAOECYiIvPFUGMBDqWpUFxWDVdHOR7q6yp2OURERO2CocYC7PylbgXhp4Z0h5WMv+VERGSe+A1n5lSaShxOVwHgtghERGTeGGrM3Fen86DVCRjSQ4lebo5il0NERNRuGGrMmCAI+h25p4ZygDAREZk3hhozdianBJdVt2FrLcXjAz3FLoeIiKhdMdSYsYYBwo8Fe8LR1lrkaoiIiNoXQ42ZqqjW4pvUfADAFA4QJiIiC8BQY6b2ny/A7apa+DjbYYR/N7HLISIiancMNWbqv0l1XU/PhPhAKuXmlUREZP4YasxQzs1y/HS1GBIJ8HQIu56IiMgyMNSYoYZp3BG9XNBdaSdyNURERB2DocbM6HQCvqwPNVPYSkNERBaEocbMnLhSjLySCjjZWmFcfw+xyyEiIuowDDVmZmdyDgBg0mAv2FrLRK6GiIio4zDUmJHS8hp8/2shAG6LQEREloehxozsPZuP6lod+ro7YkB3hdjlEBERdSiGGjOy65e6rqdnQr0hkXBtGiIisiwMNWYivVCD1NxSWEkleHJId7HLISIi6nAMNWZiZ30rzdggN3TrIhe5GiIioo7HUGMGarQ6fHUmDwAHCBMRkeVqU6jZsGED/P39YWtri5CQEBw7duyu52/btg2DBg2Cvb09PD09MWvWLBQXFzd77vbt2yGRSDB58uRGx/38/CCRSJo85s+f35ZbMCtH0q+juKwaro5yjOrjKnY5REREojA41OzYsQMxMTF48803cebMGURGRmL8+PHIzs5u9vzExETMmDEDc+bMwfnz57Fz504kJSVh7ty5Tc7NysrCa6+9hsjIyCbPJSUloaCgQP9ISEgAADzzzDOG3oLZ+e5cAQDg8YGesJKx8Y2IiCyTwd+Aq1evxpw5czB37lwEBQVhzZo18PHxQXx8fLPnnzx5En5+fliwYAH8/f0RERGBl156Cb/88kuj87RaLZ5//nm88847CAgIaPI6rq6u8PDw0D++/fZb9OzZE6NGjTL0FsxKZY0WBy4UAagLNURERJbKoFBTXV2N5ORkREVFNToeFRWFEydONHtNWFgYcnNzsW/fPgiCgKKiIuzatQsTJkxodF5sbCxcXV0xZ86cVtXx+eefY/bs2XedulxVVQW1Wt3oYW6OXboBTVUtPJxsMcSnq9jlEBERicagUHPjxg1otVq4u7s3Ou7u7o7CwsJmrwkLC8O2bdsQHR0NGxsbeHh4QKlUYt26dfpzjh8/js2bN2PTpk2tqmPPnj0oKSnBzJkz73peXFwcFAqF/uHjY36DaPfVdz09NsATUinXpiEiIsvVpgEYv28dEQShxRaTCxcuYMGCBVi+fDmSk5Oxf/9+ZGZmYt68eQAAjUaDadOmYdOmTXBxcWnV+2/evBnjx4+Hl5fXXc9bunQpSktL9Y+cnJxWvb6pqKzRIqG+62nCQG5eSUREls3KkJNdXFwgk8matMqoVKomrTcN4uLiEB4ejiVLlgAABg4cCAcHB0RGRmLFihUoKirCtWvXMHHiRP01Op2urjgrK6Snp6Nnz57657KysnDgwAHs3r37nvXK5XLI5ea7ZsuxSzdwu6oWngp2PRERERnUUmNjY4OQkBD9zKMGCQkJCAsLa/aa8vJySKWN30Ymq9s9WhAEBAYG4ty5c0hJSdE/Jk2ahNGjRyMlJaVJl9GWLVvg5ubWZEyOJfrubD4AYHwwu56IiIgMaqkBgEWLFmH69OkIDQ3FyJEjsXHjRmRnZ+u7k5YuXYq8vDxs3boVADBx4kS8+OKLiI+Px7hx41BQUICYmBgMHz5c330UHBzc6D2USmWzx3U6HbZs2YIXXngBVlYGl25WKmu0OHBRBQCYwFlPREREhoea6OhoFBcXIzY2FgUFBQgODsa+ffvg6+sLACgoKGi0Zs3MmTOh0Wiwfv16LF68GEqlEmPGjMHKlSsNLvbAgQPIzs7G7NmzDb7W3BzNuH5H15NS7HKIiIhEJxEEQRC7iI6iVquhUChQWloKJycnscu5LzHbz2BPSj7mRPjjrcf7iV0OERFRu2nt9zeXnzVBd3Y9PTaAXU9EREQAQ41Jauh68mLXExERkR5DjQlqWHBvPBfcIyIi0mOoMTHseiIiImoeQ42JYdcTERFR8xhqTMx37HoiIiJqFkONCams0eKAfq8ndj0RERHdiaHGhBzJuI6yai27noiIiJrBUGNCGmY9PTbAs8Vd0YmIiCwVQ42JuLPr6TF2PRERETXBUGMiGrqeuivt2PVERETUDIYaE6FfcC/Yg11PREREzWCoMQGc9URERHRvDDUm4M6up8HseiIiImoWQ40J+O5sw6wndj0RERG1hKGmk6us0eLgxfpZT9zriYiIqEUMNZ3cj+nseiIiImoNhppO7rcF99j1REREdDcMNZ1YZY0WBy42zHryErkaIiKizo2hphP7Mf06yuu7ngZ5K8Quh4iIqFNjqOnEvqvvepowkHs9ERER3QtDTSfFWU9ERESGYajppH5MV7HriYiIyAAMNZ3Ud+cKAbDriYiIqLUYajohdj0REREZjqGmE/rpSjHKq7XwUtiy64mIiKiVGGo6oUNpKgDAmCA3dj0RERG1EkNNJyMIwm+hJtBN5GqIiIhMB0NNJ5NRdBt5JRWwtZYirKeL2OUQERGZDIaaTuZgWt0A4bCeLrC1lolcDRERkelgqOlkDl1k1xMREVFbMNR0IrfKqnE6+xYAhhoiIiJDMdR0IkcyrkMnAIEejvBS2oldDhERkUlhqOlEDtbPehobxFYaIiIiQzHUdBK1Wh2OpDeMp3EXuRoiIiLTw1DTSSRn3YK6shbODjYY7KMUuxwiIiKTw1DTSTQsuPdQH1fIpFxFmIiIyFAMNZ3EnVsjEBERkeEYajqBnJvluKS6DZlUgsjermKXQ0REZJIYajqBhlaaYX5dobCzFrkaIiIi08RQ0wkc5AaWRERE942hRmRlVbU4eaUYAKdyExER3Q+GGpEdv3wD1VodfLvZo6erg9jlEBERmSyGGpE1jKcZ3dcNEgmnchMREbUVQ42IBEHQhxpujUBERHR/GGpEdD5fDZWmCg42Mgz3dxa7HCIiIpPGUCOigxfrWmkiertAbiUTuRoiIiLTxlAjokP1G1iO5awnIiKi+8ZQI5Lrmiqk5pQAAB4K5CrCRERE94uhRiSH61tpBnor4OZoK3I1REREpo+hRiSHuYowERGRUTHUiKC6VoejGdcBMNQQEREZC0ONCE5l3kRZtRaujnIEeynELoeIiMgsMNSIoGHBvTF93SCVchVhIiIiY2CoEcGhtCIAwGh2PRERERkNQ00Hu3r9Nq4Vl8NGJkVEbxexyyEiIjIbbQo1GzZsgL+/P2xtbRESEoJjx47d9fxt27Zh0KBBsLe3h6enJ2bNmoXi4uJmz92+fTskEgkmT57c5Lm8vDxMmzYN3bp1g729PQYPHozk5OS23IJoGrqeHghwRhe5lcjVEBERmQ+DQ82OHTsQExODN998E2fOnEFkZCTGjx+P7OzsZs9PTEzEjBkzMGfOHJw/fx47d+5EUlIS5s6d2+TcrKwsvPbaa4iMjGzy3K1btxAeHg5ra2t8//33uHDhAj766CMolUpDb0FUDVsjcNYTERGRcRkcalavXo05c+Zg7ty5CAoKwpo1a+Dj44P4+Phmzz958iT8/PywYMEC+Pv7IyIiAi+99BJ++eWXRudptVo8//zzeOeddxAQENDkdVauXAkfHx9s2bIFw4cPh5+fH8aOHYuePXsaeguiUVfWIOnaTQAMNURERMZmUKiprq5GcnIyoqKiGh2PiorCiRMnmr0mLCwMubm52LdvHwRBQFFREXbt2oUJEyY0Oi82Nhaurq6YM2dOs6+zd+9ehIaG4plnnoGbmxuGDBmCTZs23bXeqqoqqNXqRg8xHcu4gVqdgJ6uDvDt5iBqLURERObGoFBz48YNaLVauLs33oDR3d0dhYWFzV4TFhaGbdu2ITo6GjY2NvDw8IBSqcS6dev05xw/fhybN2++a0i5evUq4uPj0bt3b/zwww+YN28eFixYgK1bt7Z4TVxcHBQKhf7h4+NjyO0a3cH6WU9jg7iBJRERkbG1aaCwRNJ4bRVBEJoca3DhwgUsWLAAy5cvR3JyMvbv34/MzEzMmzcPAKDRaDBt2jRs2rQJLi4tzwbS6XQYOnQo3nvvPQwZMgQvvfQSXnzxxRa7vQBg6dKlKC0t1T9ycnLacLfGodMJOJJet4rw6L7seiIiIjI2g6bfuLi4QCaTNWmVUalUTVpvGsTFxSE8PBxLliwBAAwcOBAODg6IjIzEihUrUFRUhGvXrmHixIn6a3Q6XV1xVlZIT09Hz5494enpiX79+jV67aCgIHz55Zct1iuXyyGXyw25xXaTVqhBcVk1HGxkCPXrKnY5REREZseglhobGxuEhIQgISGh0fGEhASEhYU1e015eTmk0sZvI5PJANS18AQGBuLcuXNISUnRPyZNmoTRo0cjJSVF32UUHh6O9PT0Rq+TkZEBX19fQ25BNMcv3wAADPd3hrWMywMREREZm8ELpSxatAjTp09HaGgoRo4ciY0bNyI7O1vfnbR06VLk5eXpx7pMnDhR3000btw4FBQUICYmBsOHD4eXlxcAIDg4uNF7NEzTvvP4woULERYWhvfeew9Tp07FqVOnsHHjRmzcuLFNN97Rjl+pCzXhvbjgHhERUXswONRER0ejuLgYsbGxKCgoQHBwMPbt26dvMSkoKGi0Zs3MmTOh0Wiwfv16LF68GEqlEmPGjMHKlSsNet9hw4bhq6++wtKlSxEbGwt/f3+sWbMGzz//vKG30OGqa3X4+WrdVG6GGiIiovYhEQRBELuIjqJWq6FQKFBaWgonJ6cOe99TmTcx9V8/waWLDU795WFuYklERGSA1n5/c3BHB0isH08zsqcLAw0REVE7YajpACfqQ01Er24iV0JERGS+GGra2e2qWqTklAAAwnpyPA0REVF7YahpZ6cyi1GrE+DbzR4+zvZil0NERGS2GGraWeKlYgBspSEiImpvDDXt7MSVhvE0DDVERETtiaGmHV3XVCGtUAOJBBjZk4OEiYiI2hNDTTtqaKXp5+kEZwcbkashIiIybww17ej4ZXY9ERERdRSGmnYiCAKOX64fJMxQQ0RE1O4YatpJVnE58koqYCOTYphfV7HLISIiMnsMNe2kYVfuIT2UsLcxeN9QIiIiMhBDTTvheBoiIqKOxVDTDnQ6ASeucDwNERFRR2KoaQcXCtQoKa9BF7kVBnkrxC6HiIjIIjDUtIOGrqcRAc6wkvF/MRERUUfgN247SKwPNeHseiIiIuowDDVGVlWrRdK1mwAYaoiIiDoSQ42Rnc4qQWWNDq6OcvR26yJ2OURERBaDocbIGvZ7Cu/ZDRKJRORqiIiILAdDjZFxPA0REZE4GGqMSF1Zg9ScEgAMNURERB2NocaIfr56EzoBCHBxgJfSTuxyiIiILApDjRE1rE8T1qubyJUQERFZHoYaI+J+T0REROJhqDGSInUlLqluQyIBRgSwpYaIiKijMdQYScNU7gHdFVDa24hcDRERkeVhqDGSxEv1u3L3ZNcTERGRGBhqjEAQBH1LDcfTEBERiYOhxgiu3ihDQWklbKykCPXrKnY5REREFomhxghO1M96CvXtCltrmcjVEBERWSaGGiPg1ghERETiY6i5T1qdgJ+u1A0SZqghIiISj5XYBZi6Wp0Oyyb0w6lrNzGgu0LscoiIiCwWQ819klvJMHWYD6YO8xG7FCIiIovG7iciIiIyCww1REREZBYYaoiIiMgsMNQQERGRWWCoISIiIrPAUENERERmgaGGiIiIzAJDDREREZkFhhoiIiIyCww1REREZBYYaoiIiMgsMNQQERGRWWCoISIiIrNgUbt0C4IAAFCr1SJXQkRERK3V8L3d8D3eEosKNRqNBgDg4+MjciVERERkKI1GA4VC0eLzEuFesceM6HQ65Ofnw9HRERKJxGivq1ar4ePjg5ycHDg5ORntdTsTc79H3p/pM/d75P2ZPnO/x/a8P0EQoNFo4OXlBam05ZEzFtVSI5VK4e3t3W6v7+TkZJZ/UO9k7vfI+zN95n6PvD/TZ+732F73d7cWmgYcKExERERmgaGGiIiIzAJDjRHI5XK8/fbbkMvlYpfSbsz9Hnl/ps/c75H3Z/rM/R47w/1Z1EBhIiIiMl9sqSEiIiKzwFBDREREZoGhhoiIiMwCQw0RERGZBYYaI4mLi4NEIkFMTIzYpRhVXl4epk2bhm7dusHe3h6DBw9GcnKy2GUZRW1tLZYtWwZ/f3/Y2dkhICAAsbGx0Ol0YpfWZkePHsXEiRPh5eUFiUSCPXv2NHpeEAT89a9/hZeXF+zs7PDQQw/h/Pnz4hTbBne7v5qaGrz++usYMGAAHBwc4OXlhRkzZiA/P1+8gtvgXr+Hd3rppZcgkUiwZs2aDqvvfrXm/i5evIhJkyZBoVDA0dERI0aMQHZ2dscX2wb3ur/bt2/j5Zdfhre3N+zs7BAUFIT4+Hhxim2DuLg4DBs2DI6OjnBzc8PkyZORnp7e6BwxP2cYaowgKSkJGzduxMCBA8Uuxahu3bqF8PBwWFtb4/vvv8eFCxfw0UcfQalUil2aUaxcuRIff/wx1q9fj4sXL2LVqlX44IMPsG7dOrFLa7OysjIMGjQI69evb/b5VatWYfXq1Vi/fj2SkpLg4eGBRx55RL8vWmd3t/srLy/H6dOn8dZbb+H06dPYvXs3MjIyMGnSJBEqbbt7/R422LNnD37++Wd4eXl1UGXGca/7u3LlCiIiIhAYGIgff/wRqampeOutt2Bra9vBlbbNve5v4cKF2L9/Pz7//HNcvHgRCxcuxCuvvIKvv/66gyttmyNHjmD+/Pk4efIkEhISUFtbi6ioKJSVlenPEfVzRqD7otFohN69ewsJCQnCqFGjhFdffVXskozm9ddfFyIiIsQuo91MmDBBmD17dqNjTz31lDBt2jSRKjIuAMJXX32l/1mn0wkeHh7C+++/rz9WWVkpKBQK4eOPPxahwvvz+/trzqlTpwQAQlZWVscUZWQt3WNubq7QvXt34ddffxV8fX2Fv//97x1emzE0d3/R0dFm+3dQEAShf//+QmxsbKNjQ4cOFZYtW9aBlRmPSqUSAAhHjhwRBEH8zxm21Nyn+fPnY8KECXj44YfFLsXo9u7di9DQUDzzzDNwc3PDkCFDsGnTJrHLMpqIiAgcPHgQGRkZAIDU1FQkJibiscceE7my9pGZmYnCwkJERUXpj8nlcowaNQonTpwQsbL2U1paColEYjati0DdxrzTp0/HkiVL0L9/f7HLMSqdTofvvvsOffr0wbhx4+Dm5oYHHnjgrl1wpiYiIgJ79+5FXl4eBEHA4cOHkZGRgXHjxoldWpuUlpYCAJydnQGI/znDUHMftm/fjuTkZMTFxYldSru4evUq4uPj0bt3b/zwww+YN28eFixYgK1bt4pdmlG8/vrrePbZZxEYGAhra2sMGTIEMTExePbZZ8UurV0UFhYCANzd3Rsdd3d31z9nTiorK/HGG2/gueeeM6vNA1euXAkrKyssWLBA7FKMTqVS4fbt23j//ffx6KOP4n//+x+efPJJPPXUUzhy5IjY5RnF2rVr0a9fP3h7e8PGxgaPPvooNmzYgIiICLFLM5ggCFi0aBEiIiIQHBwMQPzPGYvapduYcnJy8Oqrr+J///ufyfT1Gkqn0yE0NBTvvfceAGDIkCE4f/484uPjMWPGDJGru387duzA559/ji+++AL9+/dHSkoKYmJi4OXlhRdeeEHs8tqNRCJp9LMgCE2Ombqamhr84Q9/gE6nw4YNG8Qux2iSk5Pxj3/8A6dPnza73zMA+kH6TzzxBBYuXAgAGDx4ME6cOIGPP/4Yo0aNErM8o1i7di1OnjyJvXv3wtfXF0ePHsWf/vQneHp6mlyL/8svv4yzZ88iMTGxyXNifc6wpaaNkpOToVKpEBISAisrK1hZWeHIkSNYu3YtrKysoNVqxS7xvnl6eqJfv36NjgUFBZnMLIR7WbJkCd544w384Q9/wIABAzB9+nQsXLjQbFvePDw8AKDJv5ZUKlWTf1WZspqaGkydOhWZmZlISEgwq1aaY8eOQaVSoUePHvrPnaysLCxevBh+fn5il3ffXFxcYGVlZbafOxUVFfjLX/6C1atXY+LEiRg4cCBefvllREdH48MPPxS7PIO88sor2Lt3Lw4fPgxvb2/9cbE/Zxhq2mjs2LE4d+4cUlJS9I/Q0FA8//zzSElJgUwmE7vE+xYeHt5kql5GRgZ8fX1Fqsi4ysvLIZU2/isgk8lMekr33fj7+8PDwwMJCQn6Y9XV1Thy5AjCwsJErMx4GgLNpUuXcODAAXTr1k3skoxq+vTpOHv2bKPPHS8vLyxZsgQ//PCD2OXdNxsbGwwbNsxsP3dqampQU1Nj0p87giDg5Zdfxu7du3Ho0CH4+/s3el7szxl2P7WRo6Ojvg+xgYODA7p169bkuKlauHAhwsLC8N5772Hq1Kk4deoUNm7ciI0bN4pdmlFMnDgR7777Lnr06IH+/fvjzJkzWL16NWbPni12aW12+/ZtXL58Wf9zZmYmUlJS4OzsjB49eiAmJgbvvfceevfujd69e+O9996Dvb09nnvuORGrbr273Z+XlxemTJmC06dP49tvv4VWq9X/a9HZ2Rk2NjZilW2Qe/0e/j6oWVtbw8PDA3379u3oUtvkXve3ZMkSREdH48EHH8To0aOxf/9+fPPNN/jxxx/FK9oA97q/UaNGYcmSJbCzs4Ovry+OHDmCrVu3YvXq1SJW3Xrz58/HF198ga+//hqOjo76v2MKhQJ2dnb69dpE+5xp9/lVFsTcpnQLgiB88803QnBwsCCXy4XAwEBh48aNYpdkNGq1Wnj11VeFHj16CLa2tkJAQIDw5ptvClVVVWKX1maHDx8WADR5vPDCC4Ig1E23fPvttwUPDw9BLpcLDz74oHDu3DlxizbA3e4vMzOz2ecACIcPHxa79Fa71+/h75nalO7W3N/mzZuFXr16Cba2tsKgQYOEPXv2iFewge51fwUFBcLMmTMFLy8vwdbWVujbt6/w0UcfCTqdTtzCW6mlv2NbtmzRnyPm54ykvkgiIiIik8YxNURERGQWGGqIiIjILDDUEBERkVlgqCEiIiKzwFBDREREZoGhhoiIiMwCQw0RERGZBYYaIiIiMgsMNURERGQWGGqIiIjILDDUEBERkVlgqCEiIiKz8P8BX5pBEiAP3ysAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf = PolynomialFeatures(degree=2)\n",
    "alphas = np.geomspace(4, 20, 20)\n",
    "scores=[]\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha, max_iter=100000)\n",
    "\n",
    "    estimator = Pipeline([\n",
    "        (\"scaler\", s),\n",
    "        (\"polynomial_features\", pf),\n",
    "        (\"ridge_regression\", ridge)])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    score = r2_score(y, predictions)\n",
    "    scores.append(score)\n",
    "\n",
    "plt.plot(alphas, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88048214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9134777735196521"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n",
    "# make the model and train it on ALL the data\n",
    "# Then release it into the wild .....\n",
    "best_estimator = Pipeline([\n",
    "                    (\"scaler\", s),\n",
    "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "                    (\"lasso_regression\", Lasso(alpha=0.03))])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "best_estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ac42f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame(zip(best_estimator.named_steps[\"make_higher_degree\"].get_feature_names_out(),\n",
    "                 best_estimator.named_steps[\"lasso_regression\"].coef_,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ac8969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_dict = dict(zip(list(range(len(X.columns.values))), X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dde2f601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CRIM',\n",
       " 1: 'ZN',\n",
       " 2: 'INDUS',\n",
       " 3: 'CHAS',\n",
       " 4: 'NOX',\n",
       " 5: 'RM',\n",
       " 6: 'AGE',\n",
       " 7: 'DIS',\n",
       " 8: 'RAD',\n",
       " 9: 'TAX',\n",
       " 10: 'PTRATIO',\n",
       " 11: 'B',\n",
       " 12: 'LSTAT'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "812b4b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>x12</td>\n",
       "      <td>-3.395426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x7</td>\n",
       "      <td>-2.561614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>x9</td>\n",
       "      <td>-1.722662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>x8 x12</td>\n",
       "      <td>-1.124408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>x5 x8</td>\n",
       "      <td>-1.085987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x8</td>\n",
       "      <td>1.127783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>x6 x8</td>\n",
       "      <td>1.363407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>x9 x10</td>\n",
       "      <td>1.962870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x5</td>\n",
       "      <td>3.326791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x0 x3</td>\n",
       "      <td>3.536536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1\n",
       "13     x12 -3.395426\n",
       "8       x7 -2.561614\n",
       "10      x9 -1.722662\n",
       "94  x8 x12 -1.124408\n",
       "72   x5 x8 -1.085987\n",
       "..     ...       ...\n",
       "9       x8  1.127783\n",
       "79   x6 x8  1.363407\n",
       "96  x9 x10  1.962870\n",
       "6       x5  3.326791\n",
       "17   x0 x3  3.536536\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importances.sort_values(by=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58edea",
   "metadata": {},
   "source": [
    "#### Grid Search CV\n",
    "To do cross-validation, we used two techniques:\n",
    "\n",
    "use KFolds and manually create a loop to do cross-validation\n",
    "use cross_val_predict and score to get a cross-valiated score in a couple of lines.\n",
    "To do hyper-parameter tuning, we see a general pattern:\n",
    "\n",
    "use cross_val_predict and score in a manually written loop over hyperparemeters, then select the best one.\n",
    "Perhaps not surprisingly, there is a function that does this for us -- GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1218b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Same estimator as before\n",
    "estimator = Pipeline([(\"scaler\", StandardScaler()),\n",
    "        (\"polynomial_features\", PolynomialFeatures()),\n",
    "        (\"ridge_regression\", Ridge())])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3],\n",
    "    'ridge_regression__alpha': np.geomspace(4, 20, 20)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93b1224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;polynomial_features&#x27;,\n",
       "                                        PolynomialFeatures()),\n",
       "                                       (&#x27;ridge_regression&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;polynomial_features__degree&#x27;: [1, 2, 3],\n",
       "                         &#x27;ridge_regression__alpha&#x27;: array([ 4.        ,  4.3535936 ,  4.73844431,  5.15731521,  5.61321363,\n",
       "        6.10941274,  6.64947505,  7.23727802,  7.87704182,  8.57335972,\n",
       "        9.331231  , 10.1560969 , 11.05387963, 12.03102491, 13.09454827,\n",
       "       14.25208539, 15.51194695, 16.88317825, 18.37562421, 20.        ])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;polynomial_features&#x27;,\n",
       "                                        PolynomialFeatures()),\n",
       "                                       (&#x27;ridge_regression&#x27;, Ridge())]),\n",
       "             param_grid={&#x27;polynomial_features__degree&#x27;: [1, 2, 3],\n",
       "                         &#x27;ridge_regression__alpha&#x27;: array([ 4.        ,  4.3535936 ,  4.73844431,  5.15731521,  5.61321363,\n",
       "        6.10941274,  6.64947505,  7.23727802,  7.87704182,  8.57335972,\n",
       "        9.331231  , 10.1560969 , 11.05387963, 12.03102491, 13.09454827,\n",
       "       14.25208539, 15.51194695, 16.88317825, 18.37562421, 20.        ])})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;polynomial_features&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;ridge_regression&#x27;, Ridge(alpha=15.511946948525646))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PolynomialFeatures<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">?<span>Documentation for PolynomialFeatures</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialFeatures()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=15.511946948525646)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('polynomial_features',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('ridge_regression', Ridge())]),\n",
       "             param_grid={'polynomial_features__degree': [1, 2, 3],\n",
       "                         'ridge_regression__alpha': array([ 4.        ,  4.3535936 ,  4.73844431,  5.15731521,  5.61321363,\n",
       "        6.10941274,  6.64947505,  7.23727802,  7.87704182,  8.57335972,\n",
       "        9.331231  , 10.1560969 , 11.05387963, 12.03102491, 13.09454827,\n",
       "       14.25208539, 15.51194695, 16.88317825, 18.37562421, 20.        ])})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9857d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8504992740007822,\n",
       " {'polynomial_features__degree': 2,\n",
       "  'ridge_regression__alpha': 15.511946948525646})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ce6a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = grid.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f09942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9146985287463713"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This includes both in-sample and out-of-sample\n",
    "r2_score(y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2af2b5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.28829772e-01, -5.05856284e-03,  1.62658971e-02,\n",
       "        1.00085587e-01, -9.67012834e-01,  3.25919745e+00, -9.57354081e-01,\n",
       "       -1.94774304e+00,  8.47932375e-01, -1.00903101e+00, -7.09489284e-01,\n",
       "        5.48320825e-01, -3.02796163e+00,  7.69588769e-02,  7.24274286e-02,\n",
       "        6.75359501e-02,  1.70458885e+00, -4.76779943e-01,  5.72065384e-01,\n",
       "        1.29769211e-01,  2.25908428e-01, -7.39176477e-01,  1.64401016e-01,\n",
       "       -7.79048916e-02, -8.46238751e-02,  4.98683957e-01,  2.15472338e-01,\n",
       "       -1.47172451e-01,  1.44110784e-01,  1.95181246e-01,  5.12046833e-02,\n",
       "       -1.10854296e-01, -2.73868352e-01, -1.31082729e-01,  7.19564832e-01,\n",
       "        5.48148586e-02,  8.81408420e-02, -2.65489851e-01,  5.80545185e-01,\n",
       "        1.07454993e-01,  9.49069101e-01,  5.68679067e-01,  5.32690017e-01,\n",
       "        6.98752649e-01, -5.91389648e-02,  7.43093700e-02, -4.26375257e-01,\n",
       "        2.35823244e-01, -6.82554161e-01,  3.39870567e-01, -9.60949439e-01,\n",
       "       -8.12827100e-01,  2.81875086e-01,  5.05015171e-02,  9.09596403e-02,\n",
       "        6.27478242e-01, -1.38350959e-01, -1.05697593e-01, -3.81805825e-01,\n",
       "       -4.48034446e-01, -4.51572263e-01, -4.89807062e-01,  7.46018959e-01,\n",
       "       -7.98434734e-01,  7.42438633e-02, -5.71696288e-01, -4.96174174e-02,\n",
       "        5.31715001e-01,  2.26611448e-01, -7.06049593e-01,  5.57918194e-02,\n",
       "       -7.86121183e-01, -9.09468994e-01, -1.02912278e+00, -1.58177551e-01,\n",
       "       -7.74956649e-01,  1.42550640e-01,  7.52412040e-02,  1.07082529e+00,\n",
       "        5.04449012e-02, -7.06160250e-02, -9.56064259e-01, -1.12279340e+00,\n",
       "        1.00934955e+00, -6.00719736e-01, -4.14052557e-01, -1.37258722e-01,\n",
       "       -2.66892679e-01,  8.21265588e-01, -8.52392067e-01,  8.75069121e-01,\n",
       "        3.67697485e-01, -1.12497890e-01, -1.11433587e+00,  8.14011054e-03,\n",
       "        1.28974396e+00, -3.62737520e-01, -1.08086194e+00, -1.18753580e-01,\n",
       "        8.42068993e-02,  1.09877090e-04, -3.62785045e-01, -4.06308662e-01,\n",
       "        8.08148961e-01])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that \"grid\" is a fit object!\n",
    "# We can use grid.predict(X_test) to get brand new predictions!\n",
    "grid.best_estimator_.named_steps['ridge_regression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "381330f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00766206, 0.00566332, 0.00632874, 0.005663  , 0.00666253,\n",
       "        0.00566451, 0.00532985, 0.00599575, 0.00599639, 0.0053304 ,\n",
       "        0.00566316, 0.00533048, 0.0063285 , 0.00599591, 0.00599631,\n",
       "        0.0049994 , 0.00599631, 0.00566125, 0.005663  , 0.00616606,\n",
       "        0.00699488, 0.0073336 , 0.00766619, 0.00766158, 0.00763655,\n",
       "        0.00721391, 0.00832971, 0.00799513, 0.00866175, 0.00766277,\n",
       "        0.00763011, 0.00766063, 0.00899458, 0.00799561, 0.00866048,\n",
       "        0.0076619 , 0.00732875, 0.00655421, 0.00690436, 0.00724244,\n",
       "        0.01563247, 0.01365757, 0.01232616, 0.01632396, 0.01265979,\n",
       "        0.01365876, 0.01465821, 0.01599121, 0.01265907, 0.01499343,\n",
       "        0.01499073, 0.0128301 , 0.01526109, 0.01432403, 0.0123268 ,\n",
       "        0.01532316, 0.01332625, 0.01399175, 0.01499128, 0.01632293]),\n",
       " 'std_fit_time': array([9.43246876e-04, 4.71145933e-04, 4.71426801e-04, 4.71258002e-04,\n",
       "        4.71145571e-04, 4.69459858e-04, 4.71201776e-04, 5.84003864e-07,\n",
       "        1.17340271e-06, 4.71314248e-04, 4.70864682e-04, 4.71932352e-04,\n",
       "        4.71089465e-04, 1.12391596e-06, 1.41338052e-03, 2.43918248e-06,\n",
       "        1.12391596e-07, 9.41223829e-04, 4.70415519e-04, 2.41874549e-04,\n",
       "        8.16145402e-04, 4.66474885e-04, 4.74469519e-04, 4.70191461e-04,\n",
       "        4.55389514e-04, 5.68553660e-04, 2.05406285e-03, 8.16729560e-04,\n",
       "        1.69847476e-03, 9.41392330e-04, 8.72268918e-04, 4.72382881e-04,\n",
       "        2.15791981e-03, 8.15658730e-04, 4.70977798e-04, 9.42178770e-04,\n",
       "        4.71202259e-04, 4.15552268e-04, 8.25520764e-04, 5.42162626e-04,\n",
       "        4.45907437e-03, 4.71033179e-04, 4.72438084e-04, 2.05366304e-03,\n",
       "        9.43415077e-04, 1.24668272e-03, 1.69856809e-03, 1.63190146e-03,\n",
       "        4.71370716e-04, 2.82788495e-03, 1.41399976e-03, 6.27543677e-04,\n",
       "        1.97074723e-03, 2.86608848e-03, 4.71819920e-04, 2.86773281e-03,\n",
       "        9.41448209e-04, 8.14977627e-04, 2.82485038e-03, 1.24653401e-03]),\n",
       " 'mean_score_time': array([0.00366378, 0.00333142, 0.00233269, 0.00301878, 0.00202576,\n",
       "        0.0033311 , 0.00300018, 0.00266536, 0.00266385, 0.0029974 ,\n",
       "        0.00233165, 0.00299851, 0.0019989 , 0.00335129, 0.00299827,\n",
       "        0.00299732, 0.00235669, 0.00299803, 0.00299851, 0.00250268,\n",
       "        0.00366473, 0.00309245, 0.00299422, 0.00333142, 0.00350563,\n",
       "        0.00336043, 0.00366418, 0.00333166, 0.00333007, 0.00316866,\n",
       "        0.00333412, 0.0039986 , 0.00366306, 0.00366441, 0.00399796,\n",
       "        0.00366441, 0.00299835, 0.00366561, 0.00337791, 0.00289583,\n",
       "        0.00497802, 0.00466402, 0.00466339, 0.00466339, 0.00499662,\n",
       "        0.00399701, 0.0049963 , 0.00499686, 0.00433095, 0.00432905,\n",
       "        0.00399733, 0.00499558, 0.00566332, 0.00466386, 0.0043304 ,\n",
       "        0.00399836, 0.00366346, 0.00399748, 0.00399685, 0.00433056]),\n",
       " 'std_score_time': array([1.69828753e-03, 4.71033179e-04, 4.70528635e-04, 2.92218150e-05,\n",
       "        3.78198973e-05, 4.71258002e-04, 4.67338258e-06, 4.71595499e-04,\n",
       "        4.72045065e-04, 8.15074796e-04, 4.71089465e-04, 4.05233662e-07,\n",
       "        5.15042996e-07, 1.24088376e-03, 8.16632449e-04, 5.94720425e-07,\n",
       "        5.06324178e-04, 1.80877156e-06, 2.97360213e-07, 4.08829957e-04,\n",
       "        4.70696004e-04, 6.90343575e-04, 3.74113792e-06, 4.71370716e-04,\n",
       "        4.06277960e-04, 4.62751620e-04, 9.42797029e-04, 4.72044864e-04,\n",
       "        4.71146214e-04, 6.17630905e-04, 4.69965469e-04, 8.15951291e-04,\n",
       "        9.43078867e-04, 4.71146576e-04, 4.05233662e-07, 9.41616812e-04,\n",
       "        1.03008599e-06, 4.71653592e-04, 4.40930395e-04, 4.24727603e-04,\n",
       "        8.16455883e-04, 9.43021933e-04, 9.42459734e-04, 1.24717191e-03,\n",
       "        1.26658896e-06, 8.15756112e-04, 8.16437402e-04, 5.61957980e-07,\n",
       "        4.71314248e-04, 4.71652146e-04, 8.15950749e-04, 8.92080638e-07,\n",
       "        4.71988758e-04, 4.71314650e-04, 4.71707569e-04, 8.16826769e-04,\n",
       "        4.70808436e-04, 2.24783192e-07, 8.16242804e-04, 1.24587577e-03]),\n",
       " 'param_polynomial_features__degree': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'param_ridge_regression__alpha': masked_array(data=[4.0, 4.353593602921549, 4.7384443148498585,\n",
       "                    5.157315214232582, 5.6132136312332355,\n",
       "                    6.109412739192265, 6.649475054738714,\n",
       "                    7.237278015274221, 7.877041817465654, 8.573359716616,\n",
       "                    9.331231004451181, 10.156096902090468,\n",
       "                    11.053879625898109, 12.03102490669371,\n",
       "                    13.094548267592895, 14.252085392734966,\n",
       "                    15.511946948525646, 16.88317825098993,\n",
       "                    18.3756242076235, 20.0, 4.0, 4.353593602921549,\n",
       "                    4.7384443148498585, 5.157315214232582,\n",
       "                    5.6132136312332355, 6.109412739192265,\n",
       "                    6.649475054738714, 7.237278015274221,\n",
       "                    7.877041817465654, 8.573359716616, 9.331231004451181,\n",
       "                    10.156096902090468, 11.053879625898109,\n",
       "                    12.03102490669371, 13.094548267592895,\n",
       "                    14.252085392734966, 15.511946948525646,\n",
       "                    16.88317825098993, 18.3756242076235, 20.0, 4.0,\n",
       "                    4.353593602921549, 4.7384443148498585,\n",
       "                    5.157315214232582, 5.6132136312332355,\n",
       "                    6.109412739192265, 6.649475054738714,\n",
       "                    7.237278015274221, 7.877041817465654, 8.573359716616,\n",
       "                    9.331231004451181, 10.156096902090468,\n",
       "                    11.053879625898109, 12.03102490669371,\n",
       "                    13.094548267592895, 14.252085392734966,\n",
       "                    15.511946948525646, 16.88317825098993,\n",
       "                    18.3756242076235, 20.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'params': [{'polynomial_features__degree': 1, 'ridge_regression__alpha': 4.0},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 4.353593602921549},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 4.7384443148498585},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 5.157315214232582},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 5.6132136312332355},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 6.109412739192265},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 6.649475054738714},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 7.237278015274221},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 7.877041817465654},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 8.573359716616},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 9.331231004451181},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 10.156096902090468},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 11.053879625898109},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 12.03102490669371},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 13.094548267592895},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 14.252085392734966},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 15.511946948525646},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 16.88317825098993},\n",
       "  {'polynomial_features__degree': 1,\n",
       "   'ridge_regression__alpha': 18.3756242076235},\n",
       "  {'polynomial_features__degree': 1, 'ridge_regression__alpha': 20.0},\n",
       "  {'polynomial_features__degree': 2, 'ridge_regression__alpha': 4.0},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 4.353593602921549},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 4.7384443148498585},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 5.157315214232582},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 5.6132136312332355},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 6.109412739192265},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 6.649475054738714},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 7.237278015274221},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 7.877041817465654},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 8.573359716616},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 9.331231004451181},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 10.156096902090468},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 11.053879625898109},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 12.03102490669371},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 13.094548267592895},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 14.252085392734966},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 15.511946948525646},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 16.88317825098993},\n",
       "  {'polynomial_features__degree': 2,\n",
       "   'ridge_regression__alpha': 18.3756242076235},\n",
       "  {'polynomial_features__degree': 2, 'ridge_regression__alpha': 20.0},\n",
       "  {'polynomial_features__degree': 3, 'ridge_regression__alpha': 4.0},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 4.353593602921549},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 4.7384443148498585},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 5.157315214232582},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 5.6132136312332355},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 6.109412739192265},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 6.649475054738714},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 7.237278015274221},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 7.877041817465654},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 8.573359716616},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 9.331231004451181},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 10.156096902090468},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 11.053879625898109},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 12.03102490669371},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 13.094548267592895},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 14.252085392734966},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 15.511946948525646},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 16.88317825098993},\n",
       "  {'polynomial_features__degree': 3,\n",
       "   'ridge_regression__alpha': 18.3756242076235},\n",
       "  {'polynomial_features__degree': 3, 'ridge_regression__alpha': 20.0}],\n",
       " 'split0_test_score': array([0.67211108, 0.67209819, 0.67208048, 0.67205716, 0.67202738,\n",
       "        0.6719902 , 0.6719446 , 0.67188948, 0.67182365, 0.67174585,\n",
       "        0.67165474, 0.67154889, 0.67142681, 0.67128692, 0.67112756,\n",
       "        0.67094698, 0.67074336, 0.67051473, 0.67025905, 0.66997409,\n",
       "        0.84255141, 0.8420115 , 0.84146799, 0.84091912, 0.84036285,\n",
       "        0.83979691, 0.83921878, 0.83862579, 0.83801512, 0.83738381,\n",
       "        0.83672883, 0.83604706, 0.83533532, 0.83459041, 0.83380909,\n",
       "        0.83298809, 0.83212415, 0.831214  , 0.83025441, 0.82924215,\n",
       "        0.46032273, 0.46982089, 0.47905587, 0.48806322, 0.49687362,\n",
       "        0.50551302, 0.51400268, 0.52235936, 0.53059548, 0.53871941,\n",
       "        0.54673575, 0.55464572, 0.5624475 , 0.57013669, 0.5777067 ,\n",
       "        0.58514924, 0.59245469, 0.59961253, 0.60661174, 0.61344108]),\n",
       " 'split1_test_score': array([0.74823479, 0.74819055, 0.74813947, 0.74808061, 0.74801288,\n",
       "        0.74793512, 0.747846  , 0.74774408, 0.74762774, 0.74749524,\n",
       "        0.74734463, 0.74717382, 0.74698049, 0.74676215, 0.74651608,\n",
       "        0.74623933, 0.74592873, 0.74558082, 0.74519187, 0.74475787,\n",
       "        0.86557853, 0.86625787, 0.86686866, 0.86740954, 0.86787963,\n",
       "        0.86827854, 0.86860632, 0.86886337, 0.86905042, 0.8691684 ,\n",
       "        0.86921839, 0.86920155, 0.86911896, 0.8689716 , 0.86876022,\n",
       "        0.86848525, 0.86814671, 0.86774415, 0.86727656, 0.8667423 ,\n",
       "        0.62240449, 0.64001868, 0.65662821, 0.67225775, 0.68693442,\n",
       "        0.7006876 , 0.71354866, 0.72555069, 0.73672825, 0.74711705,\n",
       "        0.75675363, 0.76567507, 0.77391868, 0.7815217 , 0.78852106,\n",
       "        0.79495307, 0.8008532 , 0.80625591, 0.81119439, 0.81570048]),\n",
       " 'split2_test_score': array([0.70180089, 0.70208647, 0.70238591, 0.70269903, 0.7030255 ,\n",
       "        0.7033648 , 0.70371626, 0.70407902, 0.70445199, 0.70483385,\n",
       "        0.70522304, 0.70561774, 0.70601583, 0.70641491, 0.70681224,\n",
       "        0.70720474, 0.70758895, 0.70796101, 0.70831665, 0.7086511 ,\n",
       "        0.82439713, 0.8261814 , 0.82799794, 0.82983605, 0.83168477,\n",
       "        0.83353318, 0.83537055, 0.83718657, 0.83897151, 0.84071635,\n",
       "        0.8424129 , 0.84405383, 0.84563268, 0.84714388, 0.84858264,\n",
       "        0.84994485, 0.85122696, 0.8524258 , 0.85353839, 0.85456176,\n",
       "        0.19693116, 0.22914052, 0.26022455, 0.29017017, 0.3189734 ,\n",
       "        0.34663861, 0.37317752, 0.39860825, 0.42295432, 0.44624366,\n",
       "        0.46850763, 0.48978014, 0.51009675, 0.52949396, 0.54800851,\n",
       "        0.56567675, 0.58253423, 0.59861531, 0.61395284, 0.62857805]),\n",
       " 'mean_test_score': array([0.70738225, 0.7074584 , 0.70753529, 0.70761227, 0.70768859,\n",
       "        0.70776337, 0.70783562, 0.70790419, 0.70796779, 0.70802498,\n",
       "        0.70807414, 0.70811348, 0.70814104, 0.70815466, 0.70815196,\n",
       "        0.70813035, 0.70808701, 0.70801885, 0.70792252, 0.70779435,\n",
       "        0.84417569, 0.84481692, 0.84544486, 0.8460549 , 0.84664242,\n",
       "        0.84720287, 0.84773188, 0.84822524, 0.84867902, 0.84908952,\n",
       "        0.84945338, 0.84976748, 0.85002899, 0.8502353 , 0.85038398,\n",
       "        0.85047273, 0.85049927, 0.85046132, 0.85035645, 0.85018207,\n",
       "        0.42655279, 0.4463267 , 0.46530288, 0.48349704, 0.50092715,\n",
       "        0.51761308, 0.53357629, 0.54883943, 0.56342602, 0.57736004,\n",
       "        0.59066567, 0.60336698, 0.61548764, 0.62705079, 0.63807876,\n",
       "        0.64859302, 0.65861404, 0.66816125, 0.67725299, 0.68590654]),\n",
       " 'std_test_score': array([0.03132697, 0.03129595, 0.03126372, 0.03123028, 0.0311957 ,\n",
       "        0.03116   , 0.03112322, 0.03108541, 0.03104659, 0.03100677,\n",
       "        0.03096597, 0.03092414, 0.03088124, 0.03083718, 0.03079181,\n",
       "        0.03074494, 0.03069632, 0.03064563, 0.03059247, 0.03053636,\n",
       "        0.01685142, 0.01648097, 0.01611614, 0.01576333, 0.01542923,\n",
       "        0.01512054, 0.01484383, 0.01460518, 0.01441005, 0.01426295,\n",
       "        0.01416731, 0.01412538, 0.01413811, 0.01420526, 0.01432548,\n",
       "        0.01449646, 0.01471515, 0.01497792, 0.01528078, 0.01561947,\n",
       "        0.17533244, 0.16856097, 0.16212305, 0.15602001, 0.1502468 ,\n",
       "        0.14479291, 0.13964353, 0.13478065, 0.13018424, 0.12583328,\n",
       "        0.1217068 , 0.11778462, 0.11404807, 0.11048049, 0.10706746,\n",
       "        0.10379705, 0.10065978, 0.09764852, 0.09475828, 0.09198599]),\n",
       " 'rank_test_score': array([40, 39, 38, 37, 36, 35, 33, 32, 30, 28, 27, 25, 23, 21, 22, 24, 26,\n",
       "        29, 31, 34, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,  6,\n",
       "         4,  2,  1,  3,  5,  7, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50,\n",
       "        49, 48, 47, 46, 45, 44, 43, 42, 41])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e74721ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_polynomial_features__degree</th>\n",
       "      <th>param_ridge_regression__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007662</td>\n",
       "      <td>9.432469e-04</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>1.698288e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.672111</td>\n",
       "      <td>0.748235</td>\n",
       "      <td>0.701801</td>\n",
       "      <td>0.707382</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005663</td>\n",
       "      <td>4.711459e-04</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>4.710332e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>4.353594</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.672098</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>0.702086</td>\n",
       "      <td>0.707458</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006329</td>\n",
       "      <td>4.714268e-04</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.705286e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>4.738444</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.672080</td>\n",
       "      <td>0.748139</td>\n",
       "      <td>0.702386</td>\n",
       "      <td>0.707535</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005663</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>2.922181e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5.157315</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.672057</td>\n",
       "      <td>0.748081</td>\n",
       "      <td>0.702699</td>\n",
       "      <td>0.707612</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006663</td>\n",
       "      <td>4.711456e-04</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>3.781990e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5.613214</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.672027</td>\n",
       "      <td>0.748013</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.707689</td>\n",
       "      <td>0.031196</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005665</td>\n",
       "      <td>4.694599e-04</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>6.109413</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>0.747935</td>\n",
       "      <td>0.703365</td>\n",
       "      <td>0.707763</td>\n",
       "      <td>0.031160</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005330</td>\n",
       "      <td>4.712018e-04</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>4.673383e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>6.649475</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671945</td>\n",
       "      <td>0.747846</td>\n",
       "      <td>0.703716</td>\n",
       "      <td>0.707836</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>5.840039e-07</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>4.715955e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>7.237278</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671889</td>\n",
       "      <td>0.747744</td>\n",
       "      <td>0.704079</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.031085</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>1.173403e-06</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>4.720451e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>7.877042</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671824</td>\n",
       "      <td>0.747628</td>\n",
       "      <td>0.704452</td>\n",
       "      <td>0.707968</td>\n",
       "      <td>0.031047</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005330</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>8.150748e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>8.573360</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671746</td>\n",
       "      <td>0.747495</td>\n",
       "      <td>0.704834</td>\n",
       "      <td>0.708025</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005663</td>\n",
       "      <td>4.708647e-04</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>4.710895e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>9.331231</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671655</td>\n",
       "      <td>0.747345</td>\n",
       "      <td>0.705223</td>\n",
       "      <td>0.708074</td>\n",
       "      <td>0.030966</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005330</td>\n",
       "      <td>4.719324e-04</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>10.156097</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671549</td>\n",
       "      <td>0.747174</td>\n",
       "      <td>0.705618</td>\n",
       "      <td>0.708113</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006329</td>\n",
       "      <td>4.710895e-04</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>11.053880</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671427</td>\n",
       "      <td>0.746980</td>\n",
       "      <td>0.706016</td>\n",
       "      <td>0.708141</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>1.123916e-06</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>1.240884e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>12.031025</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671287</td>\n",
       "      <td>0.746762</td>\n",
       "      <td>0.706415</td>\n",
       "      <td>0.708155</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>1.413381e-03</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>8.166324e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>13.094548</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.671128</td>\n",
       "      <td>0.746516</td>\n",
       "      <td>0.706812</td>\n",
       "      <td>0.708152</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004999</td>\n",
       "      <td>2.439182e-06</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>14.252085</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.670947</td>\n",
       "      <td>0.746239</td>\n",
       "      <td>0.707205</td>\n",
       "      <td>0.708130</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>5.063242e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>15.511947</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.670743</td>\n",
       "      <td>0.745929</td>\n",
       "      <td>0.707589</td>\n",
       "      <td>0.708087</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005661</td>\n",
       "      <td>9.412238e-04</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>1.808772e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>16.883178</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.670515</td>\n",
       "      <td>0.745581</td>\n",
       "      <td>0.707961</td>\n",
       "      <td>0.708019</td>\n",
       "      <td>0.030646</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005663</td>\n",
       "      <td>4.704155e-04</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>18.375624</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.670259</td>\n",
       "      <td>0.745192</td>\n",
       "      <td>0.708317</td>\n",
       "      <td>0.707923</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006166</td>\n",
       "      <td>2.418745e-04</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>4.088300e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.669974</td>\n",
       "      <td>0.744758</td>\n",
       "      <td>0.708651</td>\n",
       "      <td>0.707794</td>\n",
       "      <td>0.030536</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006995</td>\n",
       "      <td>8.161454e-04</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>4.706960e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.842551</td>\n",
       "      <td>0.865579</td>\n",
       "      <td>0.824397</td>\n",
       "      <td>0.844176</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007334</td>\n",
       "      <td>4.664749e-04</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>6.903436e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>4.353594</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.842011</td>\n",
       "      <td>0.866258</td>\n",
       "      <td>0.826181</td>\n",
       "      <td>0.844817</td>\n",
       "      <td>0.016481</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007666</td>\n",
       "      <td>4.744695e-04</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>3.741138e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>4.738444</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.841468</td>\n",
       "      <td>0.866869</td>\n",
       "      <td>0.827998</td>\n",
       "      <td>0.845445</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.007662</td>\n",
       "      <td>4.701915e-04</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>4.713707e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>5.157315</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.840919</td>\n",
       "      <td>0.867410</td>\n",
       "      <td>0.829836</td>\n",
       "      <td>0.846055</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.007637</td>\n",
       "      <td>4.553895e-04</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>4.062780e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>5.613214</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.840363</td>\n",
       "      <td>0.867880</td>\n",
       "      <td>0.831685</td>\n",
       "      <td>0.846642</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007214</td>\n",
       "      <td>5.685537e-04</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>4.627516e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>6.109413</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.839797</td>\n",
       "      <td>0.868279</td>\n",
       "      <td>0.833533</td>\n",
       "      <td>0.847203</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008330</td>\n",
       "      <td>2.054063e-03</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>9.427970e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>6.649475</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.839219</td>\n",
       "      <td>0.868606</td>\n",
       "      <td>0.835371</td>\n",
       "      <td>0.847732</td>\n",
       "      <td>0.014844</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.007995</td>\n",
       "      <td>8.167296e-04</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>4.720449e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7.237278</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.838626</td>\n",
       "      <td>0.868863</td>\n",
       "      <td>0.837187</td>\n",
       "      <td>0.848225</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.008662</td>\n",
       "      <td>1.698475e-03</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>4.711462e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>7.877042</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.838015</td>\n",
       "      <td>0.869050</td>\n",
       "      <td>0.838972</td>\n",
       "      <td>0.848679</td>\n",
       "      <td>0.014410</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.007663</td>\n",
       "      <td>9.413923e-04</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>6.176309e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>8.573360</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.837384</td>\n",
       "      <td>0.869168</td>\n",
       "      <td>0.840716</td>\n",
       "      <td>0.849090</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.007630</td>\n",
       "      <td>8.722689e-04</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.699655e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>9.331231</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.836729</td>\n",
       "      <td>0.869218</td>\n",
       "      <td>0.842413</td>\n",
       "      <td>0.849453</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.007661</td>\n",
       "      <td>4.723829e-04</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>8.159513e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>10.156097</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.869202</td>\n",
       "      <td>0.844054</td>\n",
       "      <td>0.849767</td>\n",
       "      <td>0.014125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.008995</td>\n",
       "      <td>2.157920e-03</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>9.430789e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>11.053880</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.835335</td>\n",
       "      <td>0.869119</td>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.850029</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.007996</td>\n",
       "      <td>8.156587e-04</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>4.711466e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>12.031025</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.834590</td>\n",
       "      <td>0.868972</td>\n",
       "      <td>0.847144</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.008660</td>\n",
       "      <td>4.709778e-04</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>13.094548</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.833809</td>\n",
       "      <td>0.868760</td>\n",
       "      <td>0.848583</td>\n",
       "      <td>0.850384</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.007662</td>\n",
       "      <td>9.421788e-04</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>9.416168e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>14.252085</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.832988</td>\n",
       "      <td>0.868485</td>\n",
       "      <td>0.849945</td>\n",
       "      <td>0.850473</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007329</td>\n",
       "      <td>4.712023e-04</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>1.030086e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>15.511947</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.832124</td>\n",
       "      <td>0.868147</td>\n",
       "      <td>0.851227</td>\n",
       "      <td>0.850499</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.006554</td>\n",
       "      <td>4.155523e-04</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>4.716536e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>16.883178</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.831214</td>\n",
       "      <td>0.867744</td>\n",
       "      <td>0.852426</td>\n",
       "      <td>0.850461</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.006904</td>\n",
       "      <td>8.255208e-04</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>4.409304e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>18.375624</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.830254</td>\n",
       "      <td>0.867277</td>\n",
       "      <td>0.853538</td>\n",
       "      <td>0.850356</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.007242</td>\n",
       "      <td>5.421626e-04</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>4.247276e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.829242</td>\n",
       "      <td>0.866742</td>\n",
       "      <td>0.854562</td>\n",
       "      <td>0.850182</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.015632</td>\n",
       "      <td>4.459074e-03</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>8.164559e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.460323</td>\n",
       "      <td>0.622404</td>\n",
       "      <td>0.196931</td>\n",
       "      <td>0.426553</td>\n",
       "      <td>0.175332</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.013658</td>\n",
       "      <td>4.710332e-04</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>9.430219e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>4.353594</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.469821</td>\n",
       "      <td>0.640019</td>\n",
       "      <td>0.229141</td>\n",
       "      <td>0.446327</td>\n",
       "      <td>0.168561</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.012326</td>\n",
       "      <td>4.724381e-04</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>9.424597e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>4.738444</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.479056</td>\n",
       "      <td>0.656628</td>\n",
       "      <td>0.260225</td>\n",
       "      <td>0.465303</td>\n",
       "      <td>0.162123</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.016324</td>\n",
       "      <td>2.053663e-03</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>1.247172e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>5.157315</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.488063</td>\n",
       "      <td>0.672258</td>\n",
       "      <td>0.290170</td>\n",
       "      <td>0.483497</td>\n",
       "      <td>0.156020</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.012660</td>\n",
       "      <td>9.434151e-04</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>1.266589e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>5.613214</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.496874</td>\n",
       "      <td>0.686934</td>\n",
       "      <td>0.318973</td>\n",
       "      <td>0.500927</td>\n",
       "      <td>0.150247</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.013659</td>\n",
       "      <td>1.246683e-03</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>8.157561e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>6.109413</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.505513</td>\n",
       "      <td>0.700688</td>\n",
       "      <td>0.346639</td>\n",
       "      <td>0.517613</td>\n",
       "      <td>0.144793</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.014658</td>\n",
       "      <td>1.698568e-03</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>8.164374e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>6.649475</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.514003</td>\n",
       "      <td>0.713549</td>\n",
       "      <td>0.373178</td>\n",
       "      <td>0.533576</td>\n",
       "      <td>0.139644</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.015991</td>\n",
       "      <td>1.631901e-03</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>5.619580e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>7.237278</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.522359</td>\n",
       "      <td>0.725551</td>\n",
       "      <td>0.398608</td>\n",
       "      <td>0.548839</td>\n",
       "      <td>0.134781</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.012659</td>\n",
       "      <td>4.713707e-04</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>7.877042</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.530595</td>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.422954</td>\n",
       "      <td>0.563426</td>\n",
       "      <td>0.130184</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.014993</td>\n",
       "      <td>2.827885e-03</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>4.716521e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>8.573360</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.538719</td>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.446244</td>\n",
       "      <td>0.577360</td>\n",
       "      <td>0.125833</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.014991</td>\n",
       "      <td>1.414000e-03</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>8.159507e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>9.331231</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.546736</td>\n",
       "      <td>0.756754</td>\n",
       "      <td>0.468508</td>\n",
       "      <td>0.590666</td>\n",
       "      <td>0.121707</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.012830</td>\n",
       "      <td>6.275437e-04</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>8.920806e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>10.156097</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.554646</td>\n",
       "      <td>0.765675</td>\n",
       "      <td>0.489780</td>\n",
       "      <td>0.603367</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.015261</td>\n",
       "      <td>1.970747e-03</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>4.719888e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>11.053880</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.562448</td>\n",
       "      <td>0.773919</td>\n",
       "      <td>0.510097</td>\n",
       "      <td>0.615488</td>\n",
       "      <td>0.114048</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.014324</td>\n",
       "      <td>2.866088e-03</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>4.713147e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>12.031025</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.570137</td>\n",
       "      <td>0.781522</td>\n",
       "      <td>0.529494</td>\n",
       "      <td>0.627051</td>\n",
       "      <td>0.110480</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.012327</td>\n",
       "      <td>4.718199e-04</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>4.717076e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>13.094548</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.577707</td>\n",
       "      <td>0.788521</td>\n",
       "      <td>0.548009</td>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.107067</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.015323</td>\n",
       "      <td>2.867733e-03</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>8.168268e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>14.252085</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.585149</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.565677</td>\n",
       "      <td>0.648593</td>\n",
       "      <td>0.103797</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.013326</td>\n",
       "      <td>9.414482e-04</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>4.708084e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>15.511947</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.592455</td>\n",
       "      <td>0.800853</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>0.658614</td>\n",
       "      <td>0.100660</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.013992</td>\n",
       "      <td>8.149776e-04</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>16.883178</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.599613</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.598615</td>\n",
       "      <td>0.668161</td>\n",
       "      <td>0.097649</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.014991</td>\n",
       "      <td>2.824850e-03</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>8.162428e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>18.375624</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.606612</td>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.677253</td>\n",
       "      <td>0.094758</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.016323</td>\n",
       "      <td>1.246534e-03</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>1.245876e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.613441</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>0.628578</td>\n",
       "      <td>0.685907</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.007662  9.432469e-04         0.003664    1.698288e-03   \n",
       "1        0.005663  4.711459e-04         0.003331    4.710332e-04   \n",
       "2        0.006329  4.714268e-04         0.002333    4.705286e-04   \n",
       "3        0.005663  4.712580e-04         0.003019    2.922181e-05   \n",
       "4        0.006663  4.711456e-04         0.002026    3.781990e-05   \n",
       "5        0.005665  4.694599e-04         0.003331    4.712580e-04   \n",
       "6        0.005330  4.712018e-04         0.003000    4.673383e-06   \n",
       "7        0.005996  5.840039e-07         0.002665    4.715955e-04   \n",
       "8        0.005996  1.173403e-06         0.002664    4.720451e-04   \n",
       "9        0.005330  4.713142e-04         0.002997    8.150748e-04   \n",
       "10       0.005663  4.708647e-04         0.002332    4.710895e-04   \n",
       "11       0.005330  4.719324e-04         0.002999    4.052337e-07   \n",
       "12       0.006329  4.710895e-04         0.001999    5.150430e-07   \n",
       "13       0.005996  1.123916e-06         0.003351    1.240884e-03   \n",
       "14       0.005996  1.413381e-03         0.002998    8.166324e-04   \n",
       "15       0.004999  2.439182e-06         0.002997    5.947204e-07   \n",
       "16       0.005996  1.123916e-07         0.002357    5.063242e-04   \n",
       "17       0.005661  9.412238e-04         0.002998    1.808772e-06   \n",
       "18       0.005663  4.704155e-04         0.002999    2.973602e-07   \n",
       "19       0.006166  2.418745e-04         0.002503    4.088300e-04   \n",
       "20       0.006995  8.161454e-04         0.003665    4.706960e-04   \n",
       "21       0.007334  4.664749e-04         0.003092    6.903436e-04   \n",
       "22       0.007666  4.744695e-04         0.002994    3.741138e-06   \n",
       "23       0.007662  4.701915e-04         0.003331    4.713707e-04   \n",
       "24       0.007637  4.553895e-04         0.003506    4.062780e-04   \n",
       "25       0.007214  5.685537e-04         0.003360    4.627516e-04   \n",
       "26       0.008330  2.054063e-03         0.003664    9.427970e-04   \n",
       "27       0.007995  8.167296e-04         0.003332    4.720449e-04   \n",
       "28       0.008662  1.698475e-03         0.003330    4.711462e-04   \n",
       "29       0.007663  9.413923e-04         0.003169    6.176309e-04   \n",
       "30       0.007630  8.722689e-04         0.003334    4.699655e-04   \n",
       "31       0.007661  4.723829e-04         0.003999    8.159513e-04   \n",
       "32       0.008995  2.157920e-03         0.003663    9.430789e-04   \n",
       "33       0.007996  8.156587e-04         0.003664    4.711466e-04   \n",
       "34       0.008660  4.709778e-04         0.003998    4.052337e-07   \n",
       "35       0.007662  9.421788e-04         0.003664    9.416168e-04   \n",
       "36       0.007329  4.712023e-04         0.002998    1.030086e-06   \n",
       "37       0.006554  4.155523e-04         0.003666    4.716536e-04   \n",
       "38       0.006904  8.255208e-04         0.003378    4.409304e-04   \n",
       "39       0.007242  5.421626e-04         0.002896    4.247276e-04   \n",
       "40       0.015632  4.459074e-03         0.004978    8.164559e-04   \n",
       "41       0.013658  4.710332e-04         0.004664    9.430219e-04   \n",
       "42       0.012326  4.724381e-04         0.004663    9.424597e-04   \n",
       "43       0.016324  2.053663e-03         0.004663    1.247172e-03   \n",
       "44       0.012660  9.434151e-04         0.004997    1.266589e-06   \n",
       "45       0.013659  1.246683e-03         0.003997    8.157561e-04   \n",
       "46       0.014658  1.698568e-03         0.004996    8.164374e-04   \n",
       "47       0.015991  1.631901e-03         0.004997    5.619580e-07   \n",
       "48       0.012659  4.713707e-04         0.004331    4.713142e-04   \n",
       "49       0.014993  2.827885e-03         0.004329    4.716521e-04   \n",
       "50       0.014991  1.414000e-03         0.003997    8.159507e-04   \n",
       "51       0.012830  6.275437e-04         0.004996    8.920806e-07   \n",
       "52       0.015261  1.970747e-03         0.005663    4.719888e-04   \n",
       "53       0.014324  2.866088e-03         0.004664    4.713147e-04   \n",
       "54       0.012327  4.718199e-04         0.004330    4.717076e-04   \n",
       "55       0.015323  2.867733e-03         0.003998    8.168268e-04   \n",
       "56       0.013326  9.414482e-04         0.003663    4.708084e-04   \n",
       "57       0.013992  8.149776e-04         0.003997    2.247832e-07   \n",
       "58       0.014991  2.824850e-03         0.003997    8.162428e-04   \n",
       "59       0.016323  1.246534e-03         0.004331    1.245876e-03   \n",
       "\n",
       "    param_polynomial_features__degree  param_ridge_regression__alpha  \\\n",
       "0                                   1                       4.000000   \n",
       "1                                   1                       4.353594   \n",
       "2                                   1                       4.738444   \n",
       "3                                   1                       5.157315   \n",
       "4                                   1                       5.613214   \n",
       "5                                   1                       6.109413   \n",
       "6                                   1                       6.649475   \n",
       "7                                   1                       7.237278   \n",
       "8                                   1                       7.877042   \n",
       "9                                   1                       8.573360   \n",
       "10                                  1                       9.331231   \n",
       "11                                  1                      10.156097   \n",
       "12                                  1                      11.053880   \n",
       "13                                  1                      12.031025   \n",
       "14                                  1                      13.094548   \n",
       "15                                  1                      14.252085   \n",
       "16                                  1                      15.511947   \n",
       "17                                  1                      16.883178   \n",
       "18                                  1                      18.375624   \n",
       "19                                  1                      20.000000   \n",
       "20                                  2                       4.000000   \n",
       "21                                  2                       4.353594   \n",
       "22                                  2                       4.738444   \n",
       "23                                  2                       5.157315   \n",
       "24                                  2                       5.613214   \n",
       "25                                  2                       6.109413   \n",
       "26                                  2                       6.649475   \n",
       "27                                  2                       7.237278   \n",
       "28                                  2                       7.877042   \n",
       "29                                  2                       8.573360   \n",
       "30                                  2                       9.331231   \n",
       "31                                  2                      10.156097   \n",
       "32                                  2                      11.053880   \n",
       "33                                  2                      12.031025   \n",
       "34                                  2                      13.094548   \n",
       "35                                  2                      14.252085   \n",
       "36                                  2                      15.511947   \n",
       "37                                  2                      16.883178   \n",
       "38                                  2                      18.375624   \n",
       "39                                  2                      20.000000   \n",
       "40                                  3                       4.000000   \n",
       "41                                  3                       4.353594   \n",
       "42                                  3                       4.738444   \n",
       "43                                  3                       5.157315   \n",
       "44                                  3                       5.613214   \n",
       "45                                  3                       6.109413   \n",
       "46                                  3                       6.649475   \n",
       "47                                  3                       7.237278   \n",
       "48                                  3                       7.877042   \n",
       "49                                  3                       8.573360   \n",
       "50                                  3                       9.331231   \n",
       "51                                  3                      10.156097   \n",
       "52                                  3                      11.053880   \n",
       "53                                  3                      12.031025   \n",
       "54                                  3                      13.094548   \n",
       "55                                  3                      14.252085   \n",
       "56                                  3                      15.511947   \n",
       "57                                  3                      16.883178   \n",
       "58                                  3                      18.375624   \n",
       "59                                  3                      20.000000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'polynomial_features__degree': 1, 'ridge_regr...           0.672111   \n",
       "1   {'polynomial_features__degree': 1, 'ridge_regr...           0.672098   \n",
       "2   {'polynomial_features__degree': 1, 'ridge_regr...           0.672080   \n",
       "3   {'polynomial_features__degree': 1, 'ridge_regr...           0.672057   \n",
       "4   {'polynomial_features__degree': 1, 'ridge_regr...           0.672027   \n",
       "5   {'polynomial_features__degree': 1, 'ridge_regr...           0.671990   \n",
       "6   {'polynomial_features__degree': 1, 'ridge_regr...           0.671945   \n",
       "7   {'polynomial_features__degree': 1, 'ridge_regr...           0.671889   \n",
       "8   {'polynomial_features__degree': 1, 'ridge_regr...           0.671824   \n",
       "9   {'polynomial_features__degree': 1, 'ridge_regr...           0.671746   \n",
       "10  {'polynomial_features__degree': 1, 'ridge_regr...           0.671655   \n",
       "11  {'polynomial_features__degree': 1, 'ridge_regr...           0.671549   \n",
       "12  {'polynomial_features__degree': 1, 'ridge_regr...           0.671427   \n",
       "13  {'polynomial_features__degree': 1, 'ridge_regr...           0.671287   \n",
       "14  {'polynomial_features__degree': 1, 'ridge_regr...           0.671128   \n",
       "15  {'polynomial_features__degree': 1, 'ridge_regr...           0.670947   \n",
       "16  {'polynomial_features__degree': 1, 'ridge_regr...           0.670743   \n",
       "17  {'polynomial_features__degree': 1, 'ridge_regr...           0.670515   \n",
       "18  {'polynomial_features__degree': 1, 'ridge_regr...           0.670259   \n",
       "19  {'polynomial_features__degree': 1, 'ridge_regr...           0.669974   \n",
       "20  {'polynomial_features__degree': 2, 'ridge_regr...           0.842551   \n",
       "21  {'polynomial_features__degree': 2, 'ridge_regr...           0.842011   \n",
       "22  {'polynomial_features__degree': 2, 'ridge_regr...           0.841468   \n",
       "23  {'polynomial_features__degree': 2, 'ridge_regr...           0.840919   \n",
       "24  {'polynomial_features__degree': 2, 'ridge_regr...           0.840363   \n",
       "25  {'polynomial_features__degree': 2, 'ridge_regr...           0.839797   \n",
       "26  {'polynomial_features__degree': 2, 'ridge_regr...           0.839219   \n",
       "27  {'polynomial_features__degree': 2, 'ridge_regr...           0.838626   \n",
       "28  {'polynomial_features__degree': 2, 'ridge_regr...           0.838015   \n",
       "29  {'polynomial_features__degree': 2, 'ridge_regr...           0.837384   \n",
       "30  {'polynomial_features__degree': 2, 'ridge_regr...           0.836729   \n",
       "31  {'polynomial_features__degree': 2, 'ridge_regr...           0.836047   \n",
       "32  {'polynomial_features__degree': 2, 'ridge_regr...           0.835335   \n",
       "33  {'polynomial_features__degree': 2, 'ridge_regr...           0.834590   \n",
       "34  {'polynomial_features__degree': 2, 'ridge_regr...           0.833809   \n",
       "35  {'polynomial_features__degree': 2, 'ridge_regr...           0.832988   \n",
       "36  {'polynomial_features__degree': 2, 'ridge_regr...           0.832124   \n",
       "37  {'polynomial_features__degree': 2, 'ridge_regr...           0.831214   \n",
       "38  {'polynomial_features__degree': 2, 'ridge_regr...           0.830254   \n",
       "39  {'polynomial_features__degree': 2, 'ridge_regr...           0.829242   \n",
       "40  {'polynomial_features__degree': 3, 'ridge_regr...           0.460323   \n",
       "41  {'polynomial_features__degree': 3, 'ridge_regr...           0.469821   \n",
       "42  {'polynomial_features__degree': 3, 'ridge_regr...           0.479056   \n",
       "43  {'polynomial_features__degree': 3, 'ridge_regr...           0.488063   \n",
       "44  {'polynomial_features__degree': 3, 'ridge_regr...           0.496874   \n",
       "45  {'polynomial_features__degree': 3, 'ridge_regr...           0.505513   \n",
       "46  {'polynomial_features__degree': 3, 'ridge_regr...           0.514003   \n",
       "47  {'polynomial_features__degree': 3, 'ridge_regr...           0.522359   \n",
       "48  {'polynomial_features__degree': 3, 'ridge_regr...           0.530595   \n",
       "49  {'polynomial_features__degree': 3, 'ridge_regr...           0.538719   \n",
       "50  {'polynomial_features__degree': 3, 'ridge_regr...           0.546736   \n",
       "51  {'polynomial_features__degree': 3, 'ridge_regr...           0.554646   \n",
       "52  {'polynomial_features__degree': 3, 'ridge_regr...           0.562448   \n",
       "53  {'polynomial_features__degree': 3, 'ridge_regr...           0.570137   \n",
       "54  {'polynomial_features__degree': 3, 'ridge_regr...           0.577707   \n",
       "55  {'polynomial_features__degree': 3, 'ridge_regr...           0.585149   \n",
       "56  {'polynomial_features__degree': 3, 'ridge_regr...           0.592455   \n",
       "57  {'polynomial_features__degree': 3, 'ridge_regr...           0.599613   \n",
       "58  {'polynomial_features__degree': 3, 'ridge_regr...           0.606612   \n",
       "59  {'polynomial_features__degree': 3, 'ridge_regr...           0.613441   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.748235           0.701801         0.707382        0.031327   \n",
       "1            0.748191           0.702086         0.707458        0.031296   \n",
       "2            0.748139           0.702386         0.707535        0.031264   \n",
       "3            0.748081           0.702699         0.707612        0.031230   \n",
       "4            0.748013           0.703025         0.707689        0.031196   \n",
       "5            0.747935           0.703365         0.707763        0.031160   \n",
       "6            0.747846           0.703716         0.707836        0.031123   \n",
       "7            0.747744           0.704079         0.707904        0.031085   \n",
       "8            0.747628           0.704452         0.707968        0.031047   \n",
       "9            0.747495           0.704834         0.708025        0.031007   \n",
       "10           0.747345           0.705223         0.708074        0.030966   \n",
       "11           0.747174           0.705618         0.708113        0.030924   \n",
       "12           0.746980           0.706016         0.708141        0.030881   \n",
       "13           0.746762           0.706415         0.708155        0.030837   \n",
       "14           0.746516           0.706812         0.708152        0.030792   \n",
       "15           0.746239           0.707205         0.708130        0.030745   \n",
       "16           0.745929           0.707589         0.708087        0.030696   \n",
       "17           0.745581           0.707961         0.708019        0.030646   \n",
       "18           0.745192           0.708317         0.707923        0.030592   \n",
       "19           0.744758           0.708651         0.707794        0.030536   \n",
       "20           0.865579           0.824397         0.844176        0.016851   \n",
       "21           0.866258           0.826181         0.844817        0.016481   \n",
       "22           0.866869           0.827998         0.845445        0.016116   \n",
       "23           0.867410           0.829836         0.846055        0.015763   \n",
       "24           0.867880           0.831685         0.846642        0.015429   \n",
       "25           0.868279           0.833533         0.847203        0.015121   \n",
       "26           0.868606           0.835371         0.847732        0.014844   \n",
       "27           0.868863           0.837187         0.848225        0.014605   \n",
       "28           0.869050           0.838972         0.848679        0.014410   \n",
       "29           0.869168           0.840716         0.849090        0.014263   \n",
       "30           0.869218           0.842413         0.849453        0.014167   \n",
       "31           0.869202           0.844054         0.849767        0.014125   \n",
       "32           0.869119           0.845633         0.850029        0.014138   \n",
       "33           0.868972           0.847144         0.850235        0.014205   \n",
       "34           0.868760           0.848583         0.850384        0.014325   \n",
       "35           0.868485           0.849945         0.850473        0.014496   \n",
       "36           0.868147           0.851227         0.850499        0.014715   \n",
       "37           0.867744           0.852426         0.850461        0.014978   \n",
       "38           0.867277           0.853538         0.850356        0.015281   \n",
       "39           0.866742           0.854562         0.850182        0.015619   \n",
       "40           0.622404           0.196931         0.426553        0.175332   \n",
       "41           0.640019           0.229141         0.446327        0.168561   \n",
       "42           0.656628           0.260225         0.465303        0.162123   \n",
       "43           0.672258           0.290170         0.483497        0.156020   \n",
       "44           0.686934           0.318973         0.500927        0.150247   \n",
       "45           0.700688           0.346639         0.517613        0.144793   \n",
       "46           0.713549           0.373178         0.533576        0.139644   \n",
       "47           0.725551           0.398608         0.548839        0.134781   \n",
       "48           0.736728           0.422954         0.563426        0.130184   \n",
       "49           0.747117           0.446244         0.577360        0.125833   \n",
       "50           0.756754           0.468508         0.590666        0.121707   \n",
       "51           0.765675           0.489780         0.603367        0.117785   \n",
       "52           0.773919           0.510097         0.615488        0.114048   \n",
       "53           0.781522           0.529494         0.627051        0.110480   \n",
       "54           0.788521           0.548009         0.638079        0.107067   \n",
       "55           0.794953           0.565677         0.648593        0.103797   \n",
       "56           0.800853           0.582534         0.658614        0.100660   \n",
       "57           0.806256           0.598615         0.668161        0.097649   \n",
       "58           0.811194           0.613953         0.677253        0.094758   \n",
       "59           0.815700           0.628578         0.685907        0.091986   \n",
       "\n",
       "    rank_test_score  \n",
       "0                40  \n",
       "1                39  \n",
       "2                38  \n",
       "3                37  \n",
       "4                36  \n",
       "5                35  \n",
       "6                33  \n",
       "7                32  \n",
       "8                30  \n",
       "9                28  \n",
       "10               27  \n",
       "11               25  \n",
       "12               23  \n",
       "13               21  \n",
       "14               22  \n",
       "15               24  \n",
       "16               26  \n",
       "17               29  \n",
       "18               31  \n",
       "19               34  \n",
       "20               20  \n",
       "21               19  \n",
       "22               18  \n",
       "23               17  \n",
       "24               16  \n",
       "25               15  \n",
       "26               14  \n",
       "27               13  \n",
       "28               12  \n",
       "29               11  \n",
       "30               10  \n",
       "31                9  \n",
       "32                8  \n",
       "33                6  \n",
       "34                4  \n",
       "35                2  \n",
       "36                1  \n",
       "37                3  \n",
       "38                5  \n",
       "39                7  \n",
       "40               60  \n",
       "41               59  \n",
       "42               58  \n",
       "43               57  \n",
       "44               56  \n",
       "45               55  \n",
       "46               54  \n",
       "47               53  \n",
       "48               52  \n",
       "49               51  \n",
       "50               50  \n",
       "51               49  \n",
       "52               48  \n",
       "53               47  \n",
       "54               46  \n",
       "55               45  \n",
       "56               44  \n",
       "57               43  \n",
       "58               42  \n",
       "59               41  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result in dataframe\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31055c04",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "We can manually generate folds by using KFolds\n",
    "We can get a score using cross_val_predict(X, y, cv=KFoldObject_or_integer). This will produce the out-of-bag prediction for each row.\n",
    "When doing hyperparameter selection, we should be optimizing on out-of-bag scores. This means either using cross_val_predict in a loop, or ....\n",
    ".... use GridSearchCV. GridSearchCV takes a model (or pipeline) and a dictionary of parameters to scan over. It finds the hyperparameter set that has the best out-of-sample score on all the parameters, and calls that it's \"best estimator\". It then retrains on all data with the \"best\" hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6b19e",
   "metadata": {},
   "source": [
    "#### Extensions\n",
    "Here are some additional items to keep in mind:\n",
    "\n",
    "There is a RandomSearchCV that tries random combination of model parameters. This can be helpful if you have a prohibitive number of combinations to test them all exhaustively.\n",
    "KFolds will randomly select rows to be in the training and test folds. There are other methods (such as StratifiedKFolds and GroupKFold, which are useful when you need more control over how the data is split (e.g. to prevent data leakage). You can create these specialized objects and pass them to the cv argument of GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2cab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a38a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d3f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
